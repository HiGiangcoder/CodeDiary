{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/abdallahwagih/kvasir-dataset-for-classification-and-segmentation\n",
      "Downloading kvasir-dataset-for-classification-and-segmentation.zip to ./kvasir-dataset-for-classification-and-segmentation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.20G/1.20G [06:57<00:00, 3.07MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import opendatasets as od\n",
    "\n",
    "data_path = 'https://www.kaggle.com/datasets/abdallahwagih/kvasir-dataset-for-classification-and-segmentation'\n",
    "od.download(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image and mask paths\n",
    "image_paths = []\n",
    "mask_paths = []\n",
    "import os\n",
    "\n",
    "images_root = './kvasir-dataset-for-classification-and-segmentation/kvasir-seg/Kvasir-SEG/images'\n",
    "masks_root = './kvasir-dataset-for-classification-and-segmentation/kvasir-seg/Kvasir-SEG/masks'\n",
    "\n",
    "for image, mask in zip(os.listdir(images_root), os.listdir(masks_root)):\n",
    "    image_paths.append(os.path.join(images_root, image))\n",
    "    mask_paths.append(os.path.join(masks_root, mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try converting images and masks to their true channel and check number of channels of images and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image:  ('R', 'G', 'B')\n",
      "Mask:  ('L',)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "print('Image: ', Image.open(image_paths[0]).convert('RGB').getbands())\n",
    "print('Mask: ', Image.open(mask_paths[0]).convert('L').getbands())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the shape of images and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images:  (530, 571, 3)\n",
      "Masks:  (530, 571)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print('Images: ', np.array(Image.open(image_paths[0]).convert('RGB')).shape)\n",
    "print('Masks: ', np.array(Image.open(mask_paths[0]).convert('L')).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show examples of data\n",
    "#### Bài tập 1: Plot ảnh từ dataset ra, đối tượng cần load là 1 cặp mẫu dữ liệu, mỗi cặp bao gồm 1 image và 1 mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m             axes[num]\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 19\u001b[0m \u001b[43mVisualize_Data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[31], line 9\u001b[0m, in \u001b[0;36mVisualize_Data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m num \u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m+\u001b[39m j\n\u001b[1;32m      8\u001b[0m nummark \u001b[38;5;241m=\u001b[39m (i \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m+\u001b[39m j\n\u001b[0;32m----> 9\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[43mimage_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnum\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     10\u001b[0m mask \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(mask_paths[num])\n\u001b[1;32m     12\u001b[0m axes[num]\u001b[38;5;241m.\u001b[39mimshow(image)\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not float"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x1000 with 60 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def Visualize_Data():\n",
    "    fig, axes = plt.subplots(10, 14, figsize=(24, 20))\n",
    "    \n",
    "    for i in range(0, 10, 2):\n",
    "        for j in range(0, 14):\n",
    "            num = i // 2 * 10 + j\n",
    "            image = Image.open(image_paths[num])\n",
    "            mask = Image.open(mask_paths[num])\n",
    "            \n",
    "            axes[i, j].imshow(image)\n",
    "            axes[i, j].axis('off')\n",
    "            \n",
    "            axes[i + 1, j].imshow(mask)\n",
    "            axes[i + 1, j].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "Visualize_Data()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into three sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  600\n",
      "Val:  200\n",
      "Test:  200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# seed = 0\n",
    "val_size = 0.2\n",
    "test_size = 0.25\n",
    "is_shuffle = True\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    image_paths,\n",
    "    mask_paths,\n",
    "    test_size=val_size,\n",
    "    random_state=42,\n",
    "    shuffle=is_shuffle\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=test_size,\n",
    "    random_state=42,\n",
    "    shuffle=is_shuffle\n",
    ")\n",
    "\n",
    "print('Train: ', len(X_train))\n",
    "print('Val: ', len(X_val))\n",
    "print('Test: ', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Kvasir Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class KvasirDataset(Dataset):\n",
    "    def __init__(self, image_paths, mask_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    # Load image and mask\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        mask_path = self.mask_paths[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "        \n",
    "        if self.transform:\n",
    "            image, mask = self.transform(image, mask)\n",
    "            \n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate mean and std of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m full_data \u001b[38;5;241m=\u001b[39m KvasirDataset(image_paths, mask_paths)\n\u001b[1;32m      3\u001b[0m img_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfull_data\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg_array\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255.0\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_array\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 17\u001b[0m, in \u001b[0;36mKvasirDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     15\u001b[0m mask_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_paths[idx]\n\u001b[1;32m     16\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(image_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m     20\u001b[0m     image, mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image, mask)\n",
      "File \u001b[0;32m~/miniconda3/envs/py3-torch/lib/python3.12/site-packages/PIL/Image.py:1143\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m   1140\u001b[0m     dither \u001b[38;5;241m=\u001b[39m Dither\u001b[38;5;241m.\u001b[39mFLOYDSTEINBERG\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1143\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdither\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m   1145\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1146\u001b[0m         \u001b[38;5;66;03m# normalize source image and try again\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create non transform dataset\n",
    "full_data = KvasirDataset(image_paths, mask_paths)\n",
    "img_data = []\n",
    "for img, _ in full_data:\n",
    "    img_array = np.array(img.resize((224, 224))) / 255.0\n",
    "    img_data.append(img_array)\n",
    "    \n",
    "img_data = np.array(img_data)\n",
    "\n",
    "# Calculate mean and std\n",
    "mean = np.mean(img_data, axis=(0, 1, 2))\n",
    "std = np.std(img_data, axis=(0, 1, 2))\n",
    "\n",
    "print('Mean: ', mean)\n",
    "print('Std: ', std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data transform and augmentation\n",
    "#### Bài tập 2: Hoàn thiện các phép biến đổi dữ liệu\n",
    "Trong bài tập này, bạn sẽ hoàn thiện các phép biến đổi (transforms) cho ảnh và mask. Các phép biến đổi này sẽ giúp chuẩn bị dữ liệu trước khi đưa vào mô hình học sâu. Gợi ý: dùng các hàm trong \"transforms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "# Define a class transform for image and mask\n",
    "class CustomTransform:\n",
    "    def __init__(self, image_transform, mask_transform):\n",
    "        self.image_transform = image_transform\n",
    "        self.mask_transform = mask_transform\n",
    "\n",
    "    def __call__(self, image, mask):\n",
    "        seed = torch.random.initial_seed()\n",
    "        torch.manual_seed(seed)\n",
    "        image = self.image_transform(image)\n",
    "\n",
    "        torch.manual_seed(seed)\n",
    "        mask = self.mask_transform(mask)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "# Train Image transforms\n",
    "train_image_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    # TODO: Chuẩn hóa ảnh với giá trị mean và std, các giá trị mean và std dùng lại mean và std đã tính ở trên\n",
    "])\n",
    "\n",
    "# Train Mask Transforms\n",
    "train_mask_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    # TODO: Chuyển mask thành nhị phân, gồm các giá trị 0 và 1\n",
    "])\n",
    "\n",
    "# Val Image transforms\n",
    "val_image_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    # TODO: Chuẩn hóa ảnh với giá trị mean và std, các giá trị mean và std dùng lại mean và std đã tính ở trên\n",
    "])\n",
    "\n",
    "# Val Mask transforms\n",
    "val_mask_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    # TODO: Chuyển mask thành nhị phân, gồm các giá trị 0 và 1\n",
    "])\n",
    "\n",
    "# Transforms dictionary\n",
    "data_transforms = {\n",
    "    'train': CustomTransform(train_image_transforms, train_mask_transforms),\n",
    "    'val': CustomTransform(val_image_transforms, val_mask_transforms),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = KvasirDataset(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    transform=data_transforms['train']\n",
    ")\n",
    "\n",
    "val_dataset = KvasirDataset(\n",
    "    X_val,\n",
    "    y_val,\n",
    "    transform=data_transforms['val']\n",
    ")\n",
    "\n",
    "test_dataset = KvasirDataset(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    transform=data_transforms['val']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "train_batch_size = 8\n",
    "test_batch_size = 4\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=test_batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=test_batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "\n",
    "# Use torchvision to display a grid of images\n",
    "def show_batch(images, masks):\n",
    "    grid_images = torchvision.utils.make_grid(images, nrow=4, normalize=True)\n",
    "    grid_masks = torchvision.utils.make_grid(masks, nrow=4, normalize=True)\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(np.transpose(grid_images, (1, 2, 0)), )\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(np.transpose(grid_masks, (1, 2, 0)), )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the images and masks\n",
    "train_features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a batch of images and masks\n",
    "show_batch(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check device availability\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "from time import time\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (15,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bài tập 3: Hoàn thành các đoạn code sau theo gợi ý"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the convolutional block\n",
    "def conv3x3(in_, out):\n",
    "    return nn.Conv2d(in_, out, 3, padding=1)\n",
    "\n",
    "# Define the ConvRelu\n",
    "class ConvRelu(nn.Module):\n",
    "    def __init__(self, in_: int, out: int):\n",
    "        super().__init__()\n",
    "        # TODO: Tạo một lớp convolution sử dụng hàm conv3x3 ở trên\n",
    "        # TODO: Tạo một lớp ReLU activation với inplace=True\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Áp dụng lớp convolution lên input x\n",
    "        # TODO: Áp dụng activation function lên output từ convolution\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels, is_deconv=True):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        # TODO: Lưu lại giá trị in_channels\n",
    "\n",
    "        # TODO: Nếu is_deconv là True, sử dụng ConvTranspose2d để tăng kích thước\n",
    "        if is_deconv:\n",
    "            self.block = nn.Sequential(\n",
    "                # TODO: Thêm một lớp ConvRelu với in_channels và middle_channels\n",
    "                # TODO: Thêm một lớp ConvTranspose2d với middle_channels và out_channels\n",
    "                # TODO: Thêm một lớp ReLU activation với inplace=True\n",
    "            )\n",
    "        # TODO: Nếu is_deconv là False, sử dụng Upsample để tăng kích thước\n",
    "        else:\n",
    "            self.block = nn.Sequential(\n",
    "                # TODO: Thêm một lớp Upsample với scale_factor=2 và mode='bilinear'\n",
    "                # TODO: Thêm một lớp ConvRelu với in_channels và middle_channels\n",
    "                # TODO: Thêm một lớp ConvRelu với middle_channels và out_channels\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Định nghĩa lớp UNet11 kế thừa từ nn.Module\n",
    "class UNet11(nn.Module):\n",
    "    def __init__(self, num_classes=1, num_filters=32, pretrained=False, is_deconv=False):\n",
    "        \"\"\"\n",
    "        :param num_classes: số lượng lớp đầu ra\n",
    "        :param num_filters: số lượng bộ lọc sử dụng trong mạng\n",
    "        :param pretrained: sử dụng mô hình VGG11 có trọng số pre-trained hay không\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # TODO: Lưu lại số lượng lớp đầu ra\n",
    "\n",
    "        # TODO: Kiểm tra nếu pretrained=True, sử dụng mô hình VGG11 với trọng số có sẵn\n",
    "        if pretrained:\n",
    "            self.encoder = models.vgg11(weights=models.vgg.VGG11_Weights.DEFAULT).features\n",
    "        else:\n",
    "            self.encoder = models.vgg11().features\n",
    "\n",
    "        # TODO: Khởi tạo hàm kích hoạt ReLU\n",
    "        # TODO: Xây dựng các khối convolutional từ các lớp trong VGG11\n",
    "        self.conv1 = nn.Sequential(\n",
    "            self.encoder[0],\n",
    "            # TODO: Thêm hàm kích hoạt ReLU\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            self.encoder[3],\n",
    "            # TODO: Thêm hàm kích hoạt ReLU\n",
    "        )\n",
    "\n",
    "        # TODO: Tiếp tục xây dựng các khối convolutional cho conv3, conv4, conv5\n",
    "        self.conv3 = nn.Sequential(\n",
    "            self.encoder[6],\n",
    "            # TODO: Thêm hàm kích hoạt ReLU\n",
    "            self.encoder[8],\n",
    "            # TODO: Thêm hàm kích hoạt ReLU\n",
    "        )\n",
    "\n",
    "        # TODO: Xây dựng khối center và decoder tương ứng\n",
    "        self.center = DecoderBlock(256 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv=is_deconv)\n",
    "        \n",
    "        # TODO: Xây dựng các lớp decoder dec5, dec4, dec3, dec2, dec1 theo kiến trúc U-Net\n",
    "\n",
    "        # TODO: Xây dựng lớp final convolution\n",
    "        self.final = nn.Conv2d(num_filters, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Thực hiện forward pass theo thứ tự các tầng conv1 -> conv5, pool giữa các tầng\n",
    "        conv1 = self.conv1(x)\n",
    "        conv2 = self.conv2(self.pool(conv1))\n",
    "        conv3 = self.conv3(self.pool(conv2))\n",
    "        # TODO: Tiếp tục cho đến conv5\n",
    "\n",
    "        # TODO: Truyền qua tầng center\n",
    "        center = self.center(self.pool(conv5))\n",
    "\n",
    "        # TODO: Ghép nối (concat) các đặc trưng từ encoder với decoder theo từng tầng\n",
    "        dec5 = self.dec5(torch.cat([center, conv5], 1))\n",
    "        # TODO: Tiếp tục với dec4, dec3, dec2, dec1\n",
    "\n",
    "        # TODO: Kiểm tra nếu num_classes > 1, sử dụng log_softmax, ngược lại sử dụng conv đầu ra\n",
    "        if self.num_classes > 1:\n",
    "            x_out = F.log_softmax(self.final(dec1), dim=1)\n",
    "        else:\n",
    "            x_out = self.final(dec1)\n",
    "\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "from torchsummary import summary\n",
    "\n",
    "model = UNet11(pretrained=True)\n",
    "model.to(device)\n",
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IOU metric\n",
    "For quality assessment, we will use the IoU (intersection over union) metric defined as:\n",
    "\n",
    "$I o U=\\frac{\\text {target } \\cap \\text { prediction }}{\\text {target } \\cup{prediction }}$\n",
    "\n",
    "### Examples:\n",
    "![alt text](https://www.jeremyjordan.me/content/images/2018/05/target_prediction.png)\n",
    "\n",
    "\n",
    "#### Intersection and union:\n",
    "\n",
    "![alt text](https://www.jeremyjordan.me/content/images/2018/05/intersection_union.png)\n",
    "\n",
    "#### Bài tập 4: Hoàn thành hàm IOU bên dưới"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_pytorch(outputs, labels):\n",
    "    outputs = outputs.squeeze().byte()  # BATCH x 1 x H x W => BATCH x H x W\n",
    "    labels = labels.squeeze().byte()\n",
    "\n",
    "    SMOOTH = 1e-8\n",
    "\n",
    "    # TODO: Tính toán phần giao nhau giữa outputs và labels\n",
    "    # intersection = ...\n",
    "\n",
    "    # TODO: Tính toán phần hợp giữa outputs và labels\n",
    "    # union = ...\n",
    "\n",
    "    # TODO: Tính toán IoU theo công thức iou theo công thức (intersection + SMOOTH) / (union + SMOOTH)\n",
    "    # iou = ...\n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "\n",
    "To start the training of our model, we will implement a loss function:\\\n",
    "**Binary cross-enthropy loss (BCE)**\n",
    "\n",
    "$$\\mathcal L_{BCE}(y, \\hat y) = -\\sum_i \\left[y_i\\log\\sigma(\\hat y_i) + (1-y_i)\\log(1-\\sigma(\\hat y_i))\\right].$$\n",
    "\n",
    "where $y$ is our target and $\\hat y$ is an output of the model. $\\sigma$ is a logistic function \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to denormalize image\n",
    "def de_normalize(img, mean=mean, std=std):\n",
    "    result = img * std + mean\n",
    "    result = np.clip(result, 0.0, 1.0)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display the result\n",
    "@torch.inference_mode()\n",
    "def display_prediction(model, image, target):\n",
    "    model.eval()\n",
    "    img = image[None,...].to(device)\n",
    "    output = model(img)\n",
    "    pred = (torch.sigmoid(output.squeeze()) > 0.5).to(int)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Input Image\")\n",
    "    plt.imshow(de_normalize(image.numpy().transpose(1,2,0)))\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.imshow(pred.cpu().squeeze(), cmap='gray')\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Ground Truth\")\n",
    "    plt.imshow(target.numpy().transpose(1, 2, 0), cmap='gray')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose one set of image, mask in train set to display\n",
    "idx = np.random.randint(0, len(train_dataset) - 1)\n",
    "display_image = train_dataset[idx][0]\n",
    "display_mask = train_dataset[idx][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate model\n",
    "def evaluate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_IOU = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            predict_labels = (torch.sigmoid(outputs.squeeze()) > 0.5).to(int)\n",
    "            val_IOU += iou_pytorch(predict_labels, labels).sum().item()\n",
    "\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_IOU = val_IOU / total\n",
    "    return val_loss, val_IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train model\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, max_epoch=50, output_path='best_model.pt'):\n",
    "    # save progress\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_IOUs = []\n",
    "    val_IOUs = []\n",
    "    best_IOU = 0.0\n",
    "    \n",
    "    # Train\n",
    "    for epoch in range(max_epoch):\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_IOU = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "            # Move inputs and labels to the device\n",
    "            inputs, labels = inputs.to(device), labels.to(device) \n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Calculate IOU\n",
    "            total += labels.size(0)\n",
    "            predict_labels = (torch.sigmoid(outputs.squeeze()) > 0.5).to(int)\n",
    "\n",
    "            running_IOU += iou_pytorch(predict_labels, labels).sum().item()\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_IOU = running_IOU / total\n",
    "        val_loss, val_IOU = evaluate(model, val_loader, criterion)\n",
    "        # Save best model\n",
    "        if val_IOU > best_IOU:\n",
    "            best_IOU = val_IOU\n",
    "            model_scripted = torch.jit.script(model) # Export to TorchScript\n",
    "            model_scripted.save(output_path) # Save\n",
    "        \n",
    "        print(f\"Epoch [{epoch + 1}/{max_epoch}], Loss: {epoch_loss:.4f}, IOU: {epoch_IOU:.2f}, Val Loss: {val_loss:.4f}, Val IOU: {val_IOU:.2f}\")\n",
    "        display_prediction(model, display_image, display_mask)\n",
    "        \n",
    "\n",
    "        # Save for plot\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_IOUs.append(epoch_IOU)\n",
    "        val_losses.append(val_loss)\n",
    "        val_IOUs.append(val_IOU)\n",
    "        \n",
    "    return [train_losses, val_losses, train_IOUs, val_IOUs]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the GPU memory just in case\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "max_epoch = 20\n",
    "lr = 4e-5\n",
    "weight_decay = 1e-4\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay = weight_decay)\n",
    "history_bce = train(model, train_loader, val_loader, criterion, optimizer, max_epoch, 'best_unet11_model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
