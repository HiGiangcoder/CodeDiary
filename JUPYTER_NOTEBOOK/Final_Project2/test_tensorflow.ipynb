{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_block(inputs, num_filters): \n",
    "\n",
    "\t# Convolution with 3x3 filter followed by ReLU activation \n",
    "\tx = tf.keras.layers.Conv2D(num_filters, \n",
    "\t\t\t\t\t\t\t3, \n",
    "\t\t\t\t\t\t\tpadding = 'valid')(inputs) \n",
    "\tx = tf.keras.layers.Activation('relu')(x) \n",
    "\t\n",
    "\t# Convolution with 3x3 filter followed by ReLU activation \n",
    "\tx = tf.keras.layers.Conv2D(num_filters, \n",
    "\t\t\t\t\t\t\t3, \n",
    "\t\t\t\t\t\t\tpadding = 'valid')(x) \n",
    "\tx = tf.keras.layers.Activation('relu')(x) \n",
    "\n",
    "\t# Max Pooling with 2x2 filter \n",
    "\tx = tf.keras.layers.MaxPool2D(pool_size = (2, 2), \n",
    "\t\t\t\t\t\t\t\tstrides = 2)(x) \n",
    "\t\n",
    "\treturn x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(inputs, skip_features, num_filters): \n",
    "\n",
    "\t# Upsampling with 2x2 filter \n",
    "\tx = tf.keras.layers.Conv2DTranspose(num_filters, \n",
    "\t\t\t\t\t\t\t\t\t\t(2, 2), \n",
    "\t\t\t\t\t\t\t\t\t\tstrides = 2, \n",
    "\t\t\t\t\t\t\t\t\t\tpadding = 'valid')(inputs) \n",
    "\t\n",
    "\t# Copy and crop the skip features \n",
    "\t# to match the shape of the upsampled input \n",
    "\tskip_features = tf.image.resize(skip_features, \n",
    "\t\t\t\t\t\t\t\t\tsize = (x.shape[1], \n",
    "\t\t\t\t\t\t\t\t\t\t\tx.shape[2])) \n",
    "\tx = tf.keras.layers.Concatenate()([x, skip_features]) \n",
    "\t\n",
    "\t# Convolution with 3x3 filter followed by ReLU activation \n",
    "\tx = tf.keras.layers.Conv2D(num_filters, \n",
    "\t\t\t\t\t\t\t3, \n",
    "\t\t\t\t\t\t\tpadding = 'valid')(x) \n",
    "\tx = tf.keras.layers.Activation('relu')(x) \n",
    "\n",
    "\t# Convolution with 3x3 filter followed by ReLU activation \n",
    "\tx = tf.keras.layers.Conv2D(num_filters, 3, padding = 'valid')(x) \n",
    "\tx = tf.keras.layers.Activation('relu')(x) \n",
    "\t\n",
    "\treturn x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-07 12:23:40.364579: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-07 12:23:44.341585: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741325025.712353   29866 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741325026.052338   29866 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-07 12:23:46.972421: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n",
      "GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 33\u001b[0m\n\u001b[1;32m     28\u001b[0m \tmodel \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mModel(inputs \u001b[38;5;241m=\u001b[39m inputs, \n\u001b[1;32m     29\u001b[0m \t\t\t\t\t\t\t\toutputs \u001b[38;5;241m=\u001b[39m outputs, \n\u001b[1;32m     30\u001b[0m \t\t\t\t\t\t\t\tname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mU-Net\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m     31\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m model \n\u001b[0;32m---> 33\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43munet_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m572\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m572\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m     34\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "Cell \u001b[0;32mIn[5], line 17\u001b[0m, in \u001b[0;36munet_model\u001b[0;34m(input_shape, num_classes)\u001b[0m\n\u001b[1;32m     14\u001b[0m b1 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mActivation(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(b1) \n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Expansive Path \u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m s5 \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m     18\u001b[0m s6 \u001b[38;5;241m=\u001b[39m decoder_block(s5, s3, \u001b[38;5;241m256\u001b[39m) \n\u001b[1;32m     19\u001b[0m s7 \u001b[38;5;241m=\u001b[39m decoder_block(s6, s2, \u001b[38;5;241m128\u001b[39m) \n",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m, in \u001b[0;36mdecoder_block\u001b[0;34m(inputs, skip_features, num_filters)\u001b[0m\n\u001b[1;32m      4\u001b[0m x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv2DTranspose(num_filters, \n\u001b[1;32m      5\u001b[0m \t\t\t\t\t\t\t\t\t(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m), \n\u001b[1;32m      6\u001b[0m \t\t\t\t\t\t\t\t\tstrides \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, \n\u001b[1;32m      7\u001b[0m \t\t\t\t\t\t\t\t\tpadding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m)(inputs) \n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Copy and crop the skip features \u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# to match the shape of the upsampled input \u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m skip_features \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mskip_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m\t\t\t\t\t\t\t\t\u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m\t\t\t\t\t\t\t\t\t\t\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     14\u001b[0m x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConcatenate()([x, skip_features]) \n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Convolution with 3x3 filter followed by ReLU activation \u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3-TF2.0/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/py3-TF2.0/lib/python3.12/site-packages/keras/src/backend/common/keras_tensor.py:138\u001b[0m, in \u001b[0;36mKerasTensor.__tf_tensor__\u001b[0;34m(self, dtype, name)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__tf_tensor__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor cannot be used as input to a TensorFlow function. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor is a symbolic placeholder for a shape and dtype, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mused when constructing Keras Functional models \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor Keras Functions. You can only use it as input to a Keras layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor a Keras operation (from the namespaces `keras.layers` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand `keras.operations`). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are likely doing something like:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = Input(...)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_fn(x)  # Invalid.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat you should do instead is wrap `tf_fn` in a layer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass MyLayer(Layer):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def call(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return tf_fn(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = MyLayer()(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
     ]
    }
   ],
   "source": [
    "def unet_model(input_shape = (256, 256, 3), num_classes = 1): \n",
    "\tinputs = tf.keras.layers.Input(input_shape) \n",
    "\t\n",
    "\t# Contracting Path \n",
    "\ts1 = encoder_block(inputs, 64) \n",
    "\ts2 = encoder_block(s1, 128) \n",
    "\ts3 = encoder_block(s2, 256) \n",
    "\ts4 = encoder_block(s3, 512) \n",
    "\t\n",
    "\t# Bottleneck \n",
    "\tb1 = tf.keras.layers.Conv2D(1024, 3, padding = 'valid')(s4) \n",
    "\tb1 = tf.keras.layers.Activation('relu')(b1) \n",
    "\tb1 = tf.keras.layers.Conv2D(1024, 3, padding = 'valid')(b1) \n",
    "\tb1 = tf.keras.layers.Activation('relu')(b1) \n",
    "\t\n",
    "\t# Expansive Path \n",
    "\ts5 = decoder_block(b1, s4, 512) \n",
    "\ts6 = decoder_block(s5, s3, 256) \n",
    "\ts7 = decoder_block(s6, s2, 128) \n",
    "\ts8 = decoder_block(s7, s1, 64) \n",
    "\t\n",
    "\t# Output \n",
    "\toutputs = tf.keras.layers.Conv2D(num_classes, \n",
    "\t\t\t\t\t\t\t\t\t1, \n",
    "\t\t\t\t\t\t\t\t\tpadding = 'valid', \n",
    "\t\t\t\t\t\t\t\t\tactivation = 'sigmoid')(s8) \n",
    "\t\n",
    "\tmodel = tf.keras.models.Model(inputs = inputs, \n",
    "\t\t\t\t\t\t\t\toutputs = outputs, \n",
    "\t\t\t\t\t\t\t\tname = 'U-Net') \n",
    "\treturn model \n",
    "\n",
    "model = unet_model(input_shape=(572, 572, 3), num_classes=2) \n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from PIL import Image \n",
    "from tensorflow.keras.preprocessing import image \n",
    "\n",
    "# Load the image \n",
    "img = Image.open('cat.png') \n",
    "# Preprocess the image \n",
    "img = img.resize((572, 572)) \n",
    "img_array = image.img_to_array(img) \n",
    "img_array = np.expand_dims(img_array[:,:,:3], axis=0) \n",
    "img_array = img_array / 255.\n",
    "\n",
    "# Load the model \n",
    "model = unet_model(input_shape=(572, 572, 3), num_classes=2) \n",
    "\n",
    "# Make predictions \n",
    "predictions = model.predict(img_array) \n",
    "\n",
    "# Convert predictions to a numpy array and resize to original image size \n",
    "predictions = np.squeeze(predictions, axis=0) \n",
    "predictions = np.argmax(predictions, axis=-1) \n",
    "predictions = Image.fromarray(np.uint8(predictions*255)) \n",
    "predictions = predictions.resize((img.width, img.height)) \n",
    "\n",
    "# Save the predicted image \n",
    "predictions.save('predicted_image.jpg') \n",
    "predictions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-TF2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
