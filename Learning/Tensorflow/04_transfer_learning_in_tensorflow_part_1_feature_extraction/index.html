<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link href=../02_neural_network_classification_in_tensorflow/ rel=prev><link href=../10_time_series_forecasting_in_tensorflow/ rel=next><link rel=icon href=../../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.7"><title>4 Transfer learning - My Documentation</title><link rel=stylesheet href=../../../assets/stylesheets/main.8608ea7d.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Merriweather:300,300i,400,400i,700,700i%7CJetBrains+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Merriweather";--md-code-font:"JetBrains Mono"}</style><link rel=stylesheet href=../../../assets/extra.css><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script> <link href="../../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style> <script src="../../../assets/javascripts/glightbox.min.js"></script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#04-transfer-learning-with-tensorflow-part-1-feature-extraction class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../../.. title="My Documentation" class="md-header__button md-logo" aria-label="My Documentation" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> My Documentation </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> 4 Transfer learning </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../../home/ class=md-tabs__link> Home </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../../AI_Model/lenet/lenet5/ class=md-tabs__link> Ki·∫øn th·ª©c l·∫≠p tr√¨nh </a> </li> <li class=md-tabs__item> <a href=../../../Subject/XSTK/Exercise2/homework/ class=md-tabs__link> M√¥n h·ªçc </a> </li> <li class=md-tabs__item> <a href=../../../Problem/general/ class=md-tabs__link> CP-Problem </a> </li> <li class=md-tabs__item> <a href=../../../other/other/ class=md-tabs__link> Other </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../.. title="My Documentation" class="md-nav__button md-logo" aria-label="My Documentation" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg> </a> My Documentation </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1> <div class="md-nav__link md-nav__container"> <a href=../../../home/ class="md-nav__link "> <span class=md-ellipsis> Home </span> </a> <label class="md-nav__link " for=__nav_1 id=__nav_1_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_1_label aria-expanded=false> <label class=md-nav__title for=__nav_1> <span class="md-nav__icon md-icon"></span> Home </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../home/about/ class=md-nav__link> <span class=md-ellipsis> About </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2 checked> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex> <span class=md-ellipsis> Ki·∫øn th·ª©c l·∫≠p tr√¨nh </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=true> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Ki·∫øn th·ª©c l·∫≠p tr√¨nh </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_1> <label class=md-nav__link for=__nav_2_1 id=__nav_2_1_label tabindex=0> <span class=md-ellipsis> C√°c ki·∫øn tr√∫c, m√¥ h√¨nh AI v√† c√°c kƒ© thu·∫≠t </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_1> <span class="md-nav__icon md-icon"></span> C√°c ki·∫øn tr√∫c, m√¥ h√¨nh AI v√† c√°c kƒ© thu·∫≠t </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_1_1> <label class=md-nav__link for=__nav_2_1_1 id=__nav_2_1_1_label tabindex=0> <span class=md-ellipsis> Lenet-5 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_1_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_1_1> <span class="md-nav__icon md-icon"></span> Lenet-5 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../AI_Model/lenet/lenet5/ class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class=md-nav__item> <a href=../../AI_Model/lenet/lenetpart1/ class=md-nav__link> <span class=md-ellipsis> Tutorial part 1 </span> </a> </li> <li class=md-nav__item> <a href=../../AI_Model/lenet/lenetpart2/ class=md-nav__link> <span class=md-ellipsis> Tutorial part 2 </span> </a> </li> <li class=md-nav__item> <a href=../../AI_Model/lenet/Lenet5_MNIST/ class=md-nav__link> <span class=md-ellipsis> Lenet-5 (Final Project 1) </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_1_2> <label class=md-nav__link for=__nav_2_1_2 id=__nav_2_1_2_label tabindex=0> <span class=md-ellipsis> UNet </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_1_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_1_2> <span class="md-nav__icon md-icon"></span> UNet </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../AI_Model/unet/unet/ class=md-nav__link> <span class=md-ellipsis> Unet tutorial </span> </a> </li> <li class=md-nav__item> <a href=../../AI_Model/unet/unet_model/ class=md-nav__link> <span class=md-ellipsis> UNet (Final Project 2) </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../AI_Model/essential/essential/ class=md-nav__link> <span class=md-ellipsis> C√°c ki·∫øn th·ª©c c·∫ßn thi·∫øt </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2> <label class=md-nav__link for=__nav_2_2 id=__nav_2_2_label tabindex=0> <span class=md-ellipsis> Python </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2> <span class="md-nav__icon md-icon"></span> Python </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Python/Numpy_1/ class=md-nav__link> <span class=md-ellipsis> Numpy 1 </span> </a> </li> <li class=md-nav__item> <a href=../../Python/Numpy_2/ class=md-nav__link> <span class=md-ellipsis> Numpy 2 </span> </a> </li> <li class=md-nav__item> <a href=../../Python/Pandas/ class=md-nav__link> <span class=md-ellipsis> Pandas </span> </a> </li> <li class=md-nav__item> <a href=../../Python/Python_Pandas_exercise1/ class=md-nav__link> <span class=md-ellipsis> Pandas exercise 1 </span> </a> </li> <li class=md-nav__item> <a href=../../Python/Pandas2/ class=md-nav__link> <span class=md-ellipsis> Pandas 2 </span> </a> </li> <li class=md-nav__item> <a href=../../Python/Python_Pandas_exercise2/ class=md-nav__link> <span class=md-ellipsis> Pandas exercise 2 </span> </a> </li> <li class=md-nav__item> <a href=../../Python/Pandas_Join_Combine/ class=md-nav__link> <span class=md-ellipsis> Pandas Join Combine </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3> <label class=md-nav__link for=__nav_2_3 id=__nav_2_3_label tabindex=0> <span class=md-ellipsis> PyTorch </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3> <span class="md-nav__icon md-icon"></span> PyTorch </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../Pytorch/00_pytorch_fundamentals/ class=md-nav__link> <span class=md-ellipsis> 0 Pytorch Fundamentals (ipynb) </span> </a> </li> <li class=md-nav__item> <a href=../../Pytorch/00_pytorch_and_deep_learning_fundamentals.pdf class=md-nav__link> <span class=md-ellipsis> 0 Deep learning fundamentals (pdf) </span> </a> </li> <li class=md-nav__item> <a href=../../Pytorch/01_pytorch_workflow/ class=md-nav__link> <span class=md-ellipsis> 1 Pytorch workflow (ipynb) </span> </a> </li> <li class=md-nav__item> <a href=../../Pytorch/01_pytorch_workflow.pdf class=md-nav__link> <span class=md-ellipsis> 1 Pytorch workflow (pdf) </span> </a> </li> <li class=md-nav__item> <a href=../../Pytorch/02_pytorch_classification/ class=md-nav__link> <span class=md-ellipsis> 2 classification (ipynb) </span> </a> </li> <li class=md-nav__item> <a href=../../Pytorch/03_pytorch_computer_vision/ class=md-nav__link> <span class=md-ellipsis> 3 Computer vision (ipynb) </span> </a> </li> <li class=md-nav__item> <a href=../../Pytorch/03_pytorch_computer_vision.pdf class=md-nav__link> <span class=md-ellipsis> 3 Compupter vision (pdf) </span> </a> </li> <li class=md-nav__item> <a href=../../Pytorch/04_pytorch_custom_datasets/ class=md-nav__link> <span class=md-ellipsis> 4 Custom datasets (pdf) </span> </a> </li> <li class=md-nav__item> <a href=../../Pytorch/05_pytorch_going_modular.pdf class=md-nav__link> <span class=md-ellipsis> 5 Going moduler (pdf) </span> </a> </li> <li class=md-nav__item> <a href=../../Pytorch/06_pytorch_transfer_learning/ class=md-nav__link> <span class=md-ellipsis> 6 Transfer learning (ipynb) </span> </a> </li> <li class=md-nav__item> <a href=../../Pytorch/06_pytorch_transfer_learning.pdf class=md-nav__link> <span class=md-ellipsis> 6 Transfer learning (pdf) </span> </a> </li> <li class=md-nav__item> <a href=../../Pytorch/07_pytorch_experiment_tracking/ class=md-nav__link> <span class=md-ellipsis> 7 Experiment tracking (ipynb) </span> </a> </li> <li class=md-nav__item> <a href=../../Pytorch/07_pytorch_experiment_tracking.pdf class=md-nav__link> <span class=md-ellipsis> 7 Experiment tracking (pdf) </span> </a> </li> <li class=md-nav__item> <a href=../../Pytorch/08_pytorch_paper_replicating/ class=md-nav__link> <span class=md-ellipsis> 8 Paper replicating (ipynb) </span> </a> </li> <li class=md-nav__item> <a href=../../Pytorch/08_pytorch_paper_replicating.pdf class=md-nav__link> <span class=md-ellipsis> 8 Paper replicating (pdf) </span> </a> </li> <li class=md-nav__item> <a href=../../Pytorch/09_pytorch_model_deployment.pdf class=md-nav__link> <span class=md-ellipsis> 9 Model deployment(pdf) </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_4 checked> <label class=md-nav__link for=__nav_2_4 id=__nav_2_4_label tabindex=0> <span class=md-ellipsis> Tensorflow </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_4_label aria-expanded=true> <label class=md-nav__title for=__nav_2_4> <span class="md-nav__icon md-icon"></span> Tensorflow </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../00_tensorflow_fundamentals/ class=md-nav__link> <span class=md-ellipsis> 0 Tensorflow fundamentals </span> </a> </li> <li class=md-nav__item> <a href=../01_neural_network_regression_in_tensorflow/ class=md-nav__link> <span class=md-ellipsis> 1 Neural network regression </span> </a> </li> <li class=md-nav__item> <a href=../02_neural_network_classification_in_tensorflow/ class=md-nav__link> <span class=md-ellipsis> 2 Neural network classification </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> 4 Transfer learning </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> 4 Transfer learning </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#what-were-going-to-cover class=md-nav__link> <span class=md-ellipsis> What we're going to cover </span> </a> </li> <li class=md-nav__item> <a href=#how-you-can-use-this-notebook class=md-nav__link> <span class=md-ellipsis> How you can use this notebook </span> </a> </li> <li class=md-nav__item> <a href=#using-a-gpu class=md-nav__link> <span class=md-ellipsis> Using a GPU </span> </a> </li> <li class=md-nav__item> <a href=#transfer-leanring-with-tensorflow-hub-getting-great-results-with-10-of-the-data class=md-nav__link> <span class=md-ellipsis> Transfer leanring with TensorFlow Hub: Getting great results with 10% of the data </span> </a> </li> <li class=md-nav__item> <a href=#downloading-and-becoming-one-with-the-data class=md-nav__link> <span class=md-ellipsis> Downloading and becoming one with the data </span> </a> </li> <li class=md-nav__item> <a href=#creating-data-loaders-preparing-the-data class=md-nav__link> <span class=md-ellipsis> Creating data loaders (preparing the data) </span> </a> </li> <li class=md-nav__item> <a href=#setting-up-callbacks-things-to-run-whilst-our-model-trains class=md-nav__link> <span class=md-ellipsis> Setting up callbacks (things to run whilst our model trains) </span> </a> </li> <li class=md-nav__item> <a href=#creating-models-using-tensorflow-hub class=md-nav__link> <span class=md-ellipsis> Creating models using TensorFlow Hub </span> </a> </li> <li class=md-nav__item> <a href=#comparing-models-using-tensorboard class=md-nav__link> <span class=md-ellipsis> Comparing models using TensorBoard </span> </a> <nav class=md-nav aria-label="Comparing models using TensorBoard"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#uploading-experiments-to-tensorboard class=md-nav__link> <span class=md-ellipsis> Uploading experiments to TensorBoard </span> </a> </li> <li class=md-nav__item> <a href=#listing-experiments-youve-saved-to-tensorboard class=md-nav__link> <span class=md-ellipsis> Listing experiments you've saved to TensorBoard </span> </a> </li> <li class=md-nav__item> <a href=#deleting-experiments-from-tensorboard class=md-nav__link> <span class=md-ellipsis> Deleting experiments from TensorBoard </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#exercises class=md-nav__link> <span class=md-ellipsis> üõ† Exercises </span> </a> </li> <li class=md-nav__item> <a href=#extra-curriculum class=md-nav__link> <span class=md-ellipsis> üìñ Extra-curriculum </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../10_time_series_forecasting_in_tensorflow/ class=md-nav__link> <span class=md-ellipsis> 10 Time series forecasting </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../OOP_Practice/ class=md-nav__link> <span class=md-ellipsis> OOP Practice </span> </a> </li> <li class=md-nav__item> <a href=../../Visualization/ class=md-nav__link> <span class=md-ellipsis> Visualization </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> M√¥n h·ªçc </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> M√¥n h·ªçc </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_1> <label class=md-nav__link for=__nav_3_1 id=__nav_3_1_label tabindex=0> <span class=md-ellipsis> X√°c su·∫•t th·ªëng k√™ </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_1_label aria-expanded=false> <label class=md-nav__title for=__nav_3_1> <span class="md-nav__icon md-icon"></span> X√°c su·∫•t th·ªëng k√™ </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../Subject/XSTK/Exercise2/homework/ class=md-nav__link> <span class=md-ellipsis> B√†i t·∫≠p v·ªÅ nh√† bu·ªïi 2 </span> </a> </li> <li class=md-nav__item> <a href=../../../Subject/XSTK/Exercise3/homework/ class=md-nav__link> <span class=md-ellipsis> B√†i t·∫≠p v·ªÅ nh√† bu·ªïi 3 </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> CP-Problem </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> CP-Problem </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../Problem/general/ class=md-nav__link> <span class=md-ellipsis> General </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_2> <label class=md-nav__link for=__nav_4_2 id=__nav_4_2_label tabindex=0> <span class=md-ellipsis> COCI 2006 2007 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_2_label aria-expanded=false> <label class=md-nav__title for=__nav_4_2> <span class="md-nav__icon md-icon"></span> COCI 2006 2007 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../Problem/coci0607/Overview/ class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_2_2> <label class=md-nav__link for=__nav_4_2_2 id=__nav_4_2_2_label tabindex=0> <span class=md-ellipsis> Contest 1 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_4_2_2_label aria-expanded=false> <label class=md-nav__title for=__nav_4_2_2> <span class="md-nav__icon md-icon"></span> Contest 1 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest1/P1_MODULO/ class=md-nav__link> <span class=md-ellipsis> MODULO </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest1/P2_HERMAN/ class=md-nav__link> <span class=md-ellipsis> HERMAN </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest1/P3_OKVIRI/ class=md-nav__link> <span class=md-ellipsis> OKVIRI </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest1/P4_SLIKAR/ class=md-nav__link> <span class=md-ellipsis> SLIKAR </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest1/P5_BOND/ class=md-nav__link> <span class=md-ellipsis> BOND </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest1/P6_DEBUG/ class=md-nav__link> <span class=md-ellipsis> DEBUG </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_2_3> <label class=md-nav__link for=__nav_4_2_3 id=__nav_4_2_3_label tabindex=0> <span class=md-ellipsis> Contest 2 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_4_2_3_label aria-expanded=false> <label class=md-nav__title for=__nav_4_2_3> <span class="md-nav__icon md-icon"></span> Contest 2 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest2/P1_R2/ class=md-nav__link> <span class=md-ellipsis> R2 </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest2/P2_ABC/ class=md-nav__link> <span class=md-ellipsis> ABC </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest2/P3_KOLONE/ class=md-nav__link> <span class=md-ellipsis> KOLONE </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest2/P4_SJECISTA/ class=md-nav__link> <span class=md-ellipsis> SJECISTA </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest2/P5_STOL/ class=md-nav__link> <span class=md-ellipsis> STOL </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest2/P6_STRAZA/ class=md-nav__link> <span class=md-ellipsis> STRAZA </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_2_4> <label class=md-nav__link for=__nav_4_2_4 id=__nav_4_2_4_label tabindex=0> <span class=md-ellipsis> Contest 3 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_4_2_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4_2_4> <span class="md-nav__icon md-icon"></span> Contest 3 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest3/P1_PATULJCI/ class=md-nav__link> <span class=md-ellipsis> PATULJCI </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest3/P2_NPUZZLE/ class=md-nav__link> <span class=md-ellipsis> NPUZZLE </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest3/P3_TROJKE/ class=md-nav__link> <span class=md-ellipsis> TROJKE </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest3/P4_TENKICI/ class=md-nav__link> <span class=md-ellipsis> TENKICI </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest3/P5_BICIKLI/ class=md-nav__link> <span class=md-ellipsis> BICIKLI </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest3/P6_LISTA/ class=md-nav__link> <span class=md-ellipsis> LISTA </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_2_5> <label class=md-nav__link for=__nav_4_2_5 id=__nav_4_2_5_label tabindex=0> <span class=md-ellipsis> Contest 4 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_4_2_5_label aria-expanded=false> <label class=md-nav__title for=__nav_4_2_5> <span class="md-nav__icon md-icon"></span> Contest 4 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest4/P1_Sibice/ class=md-nav__link> <span class=md-ellipsis> SIBICE </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest4/P2_Skener/ class=md-nav__link> <span class=md-ellipsis> SKENER </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest4/P3_Prsteni/ class=md-nav__link> <span class=md-ellipsis> PRSTENI </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest4/P4_Zbrka/ class=md-nav__link> <span class=md-ellipsis> ZBRKA </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest4/P5_Jogurt/ class=md-nav__link> <span class=md-ellipsis> JOGURT </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest4/P6_Ispiti/ class=md-nav__link> <span class=md-ellipsis> ISPITI </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_2_6> <label class=md-nav__link for=__nav_4_2_6 id=__nav_4_2_6_label tabindex=0> <span class=md-ellipsis> Contest 5 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_4_2_6_label aria-expanded=false> <label class=md-nav__title for=__nav_4_2_6> <span class="md-nav__icon md-icon"></span> Contest 5 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest5/P1_Trik/ class=md-nav__link> <span class=md-ellipsis> TRIK </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest5/P2_Natrij/ class=md-nav__link> <span class=md-ellipsis> NATRIJ </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest5/P3_Tenis/ class=md-nav__link> <span class=md-ellipsis> TENIS </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest5/P4_Liga/ class=md-nav__link> <span class=md-ellipsis> LIGA </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest5/P5_Ivana/ class=md-nav__link> <span class=md-ellipsis> IVANA </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest5/P6_Dvaput/ class=md-nav__link> <span class=md-ellipsis> DVAPUT </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_2_7> <label class=md-nav__link for=__nav_4_2_7 id=__nav_4_2_7_label tabindex=0> <span class=md-ellipsis> Contest 6 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_4_2_7_label aria-expanded=false> <label class=md-nav__title for=__nav_4_2_7> <span class="md-nav__icon md-icon"></span> Contest 6 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest6/P1_PRASE/ class=md-nav__link> <span class=md-ellipsis> PRASE </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest6/P2_MAGIJA/ class=md-nav__link> <span class=md-ellipsis> MAGIJA </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest6/P3_MARATON/ class=md-nav__link> <span class=md-ellipsis> MARATON </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest6/P4_KAMEN/ class=md-nav__link> <span class=md-ellipsis> KAMEN </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest6/P5_V/ class=md-nav__link> <span class=md-ellipsis> V </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Contest6/P6_PROSTOR/ class=md-nav__link> <span class=md-ellipsis> PROSTOR </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_2_8> <label class=md-nav__link for=__nav_4_2_8 id=__nav_4_2_8_label tabindex=0> <span class=md-ellipsis> Regional </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_4_2_8_label aria-expanded=false> <label class=md-nav__title for=__nav_4_2_8> <span class="md-nav__icon md-icon"></span> Regional </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../Problem/coci0607/Regional/P1_BARD/ class=md-nav__link> <span class=md-ellipsis> BARD </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Regional/P2_TETRIS/ class=md-nav__link> <span class=md-ellipsis> TETRIS </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Regional/P4_CIRCLE/ class=md-nav__link> <span class=md-ellipsis> CIRCLE </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_2_9> <label class=md-nav__link for=__nav_4_2_9 id=__nav_4_2_9_label tabindex=0> <span class=md-ellipsis> Croatian Olympiad </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_4_2_9_label aria-expanded=false> <label class=md-nav__title for=__nav_4_2_9> <span class="md-nav__icon md-icon"></span> Croatian Olympiad </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../Problem/coci0607/Olympiad/P1_PATRIK/ class=md-nav__link> <span class=md-ellipsis> PATRIK </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Olympiad/P2_POLICIJA/ class=md-nav__link> <span class=md-ellipsis> POLICIJA </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0607/Olympiad/P3_SABOR/ class=md-nav__link> <span class=md-ellipsis> SABOR </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_3> <label class=md-nav__link for=__nav_4_3 id=__nav_4_3_label tabindex=0> <span class=md-ellipsis> COCI 2007 2008 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_3_label aria-expanded=false> <label class=md-nav__title for=__nav_4_3> <span class="md-nav__icon md-icon"></span> COCI 2007 2008 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../Problem/coci0708/Overview/ class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_3_2> <label class=md-nav__link for=__nav_4_3_2 id=__nav_4_3_2_label tabindex=0> <span class=md-ellipsis> Contest 1 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_4_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_4_3_2> <span class="md-nav__icon md-icon"></span> Contest 1 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../Problem/coci0708/Contest1/P1_CETVRTA/ class=md-nav__link> <span class=md-ellipsis> CETVRTA </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0708/Contest1/P2_PEG/ class=md-nav__link> <span class=md-ellipsis> PEG </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0708/Contest1/P3_PRINOVA/ class=md-nav__link> <span class=md-ellipsis> PRINOVA </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0708/Contest1/P4_ZAPIS/ class=md-nav__link> <span class=md-ellipsis> ZAPIS </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0708/Contest1/P5_SREDNJI/ class=md-nav__link> <span class=md-ellipsis> SREDNJI </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0708/Contest1/P6_STAZA/ class=md-nav__link> <span class=md-ellipsis> STAZA </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_3_3> <label class=md-nav__link for=__nav_4_3_3 id=__nav_4_3_3_label tabindex=0> <span class=md-ellipsis> Contest 4 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_4_3_3_label aria-expanded=false> <label class=md-nav__title for=__nav_4_3_3> <span class="md-nav__icon md-icon"></span> Contest 4 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../Problem/coci0708/Contest4/P1_CIRCLE/ class=md-nav__link> <span class=md-ellipsis> CIRCLE </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0708/Contest4/P2_VECI/ class=md-nav__link> <span class=md-ellipsis> VECI </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0708/Contest4/P3_LEKTIRA/ class=md-nav__link> <span class=md-ellipsis> LEKTIRA </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0708/Contest4/P4_MUZICARI/ class=md-nav__link> <span class=md-ellipsis> MUZICARI </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0708/Contest4/P5_POKLON/ class=md-nav__link> <span class=md-ellipsis> POKLON </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0708/Contest4/P6_KOCKE/ class=md-nav__link> <span class=md-ellipsis> KOCKE </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_3_4> <label class=md-nav__link for=__nav_4_3_4 id=__nav_4_3_4_label tabindex=0> <span class=md-ellipsis> Contest 6 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_4_3_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4_3_4> <span class="md-nav__icon md-icon"></span> Contest 6 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../Problem/coci0708/Contest6/P1_PARKING/ class=md-nav__link> <span class=md-ellipsis> PARKING </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0708/Contest6/P2_SEMAFORI/ class=md-nav__link> <span class=md-ellipsis> SEMAFORI </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0708/Contest6/P3_GRANICA/ class=md-nav__link> <span class=md-ellipsis> GRANICA </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0708/Contest6/P4_GEORGE/ class=md-nav__link> <span class=md-ellipsis> GEORGE </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0708/Contest6/P5_PRINCEZA/ class=md-nav__link> <span class=md-ellipsis> PRINCEZA </span> </a> </li> <li class=md-nav__item> <a href=../../../Problem/coci0708/Contest6/P6_CESTARINE/ class=md-nav__link> <span class=md-ellipsis> CESTARINE </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../other/other/ class=md-nav__link> <span class=md-ellipsis> Other </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#what-were-going-to-cover class=md-nav__link> <span class=md-ellipsis> What we're going to cover </span> </a> </li> <li class=md-nav__item> <a href=#how-you-can-use-this-notebook class=md-nav__link> <span class=md-ellipsis> How you can use this notebook </span> </a> </li> <li class=md-nav__item> <a href=#using-a-gpu class=md-nav__link> <span class=md-ellipsis> Using a GPU </span> </a> </li> <li class=md-nav__item> <a href=#transfer-leanring-with-tensorflow-hub-getting-great-results-with-10-of-the-data class=md-nav__link> <span class=md-ellipsis> Transfer leanring with TensorFlow Hub: Getting great results with 10% of the data </span> </a> </li> <li class=md-nav__item> <a href=#downloading-and-becoming-one-with-the-data class=md-nav__link> <span class=md-ellipsis> Downloading and becoming one with the data </span> </a> </li> <li class=md-nav__item> <a href=#creating-data-loaders-preparing-the-data class=md-nav__link> <span class=md-ellipsis> Creating data loaders (preparing the data) </span> </a> </li> <li class=md-nav__item> <a href=#setting-up-callbacks-things-to-run-whilst-our-model-trains class=md-nav__link> <span class=md-ellipsis> Setting up callbacks (things to run whilst our model trains) </span> </a> </li> <li class=md-nav__item> <a href=#creating-models-using-tensorflow-hub class=md-nav__link> <span class=md-ellipsis> Creating models using TensorFlow Hub </span> </a> </li> <li class=md-nav__item> <a href=#comparing-models-using-tensorboard class=md-nav__link> <span class=md-ellipsis> Comparing models using TensorBoard </span> </a> <nav class=md-nav aria-label="Comparing models using TensorBoard"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#uploading-experiments-to-tensorboard class=md-nav__link> <span class=md-ellipsis> Uploading experiments to TensorBoard </span> </a> </li> <li class=md-nav__item> <a href=#listing-experiments-youve-saved-to-tensorboard class=md-nav__link> <span class=md-ellipsis> Listing experiments you've saved to TensorBoard </span> </a> </li> <li class=md-nav__item> <a href=#deleting-experiments-from-tensorboard class=md-nav__link> <span class=md-ellipsis> Deleting experiments from TensorBoard </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#exercises class=md-nav__link> <span class=md-ellipsis> üõ† Exercises </span> </a> </li> <li class=md-nav__item> <a href=#extra-curriculum class=md-nav__link> <span class=md-ellipsis> üìñ Extra-curriculum </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <p><a href=https://colab.research.google.com/github/mrdbourke/tensorflow-deep-learning/blob/main/04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb target=_parent><img src=https://colab.research.google.com/assets/colab-badge.svg alt="Open In Colab"></a></p> <h1 id=04-transfer-learning-with-tensorflow-part-1-feature-extraction>04. Transfer Learning with TensorFlow Part 1: Feature Extraction</h1> <p>We've built a bunch of convolutional neural networks from scratch and they all seem to be learning, however, there is still plenty of room for improvement.</p> <p>To improve our model(s), we could spend a while trying different configurations, adding more layers, changing the learning rate, adjusting the number of neurons per layer and more.</p> <p>However, doing this is very time consuming.</p> <p>Luckily, there's a technique we can use to save time.</p> <p>It's called <strong>transfer learning</strong>, in other words, taking the patterns (also called weights) another model has learned from another problem and using them for our own problem.</p> <p>There are two main benefits to using transfer learning: 1. Can leverage an existing neural network architecture proven to work on problems similar to our own. 2. Can leverage a working neural network architecture which has <strong>already learned</strong> patterns on similar data to our own. This often results in achieving great results with less custom data.</p> <p>What this means is, instead of hand-crafting our own neural network architectures or building them from scratch, we can utilise models which have worked for others.</p> <p>And instead of training our own models from scratch on our own datasets, we can take the patterns a model has learned from datasets such as <a href=http://www.image-net.org/ >ImageNet</a> (millions of images of different objects) and use them as the foundation of our own. Doing this often leads to getting great results with less data.</p> <p>Over the next few notebooks, we'll see the power of transfer learning in action.</p> <h2 id=what-were-going-to-cover>What we're going to cover</h2> <p>We're going to go through the following with TensorFlow:</p> <ul> <li>Introduce transfer learning (a way to beat all of our old self-built models)</li> <li>Using a smaller dataset to experiment faster (10% of training samples of 10 classes of food)</li> <li>Build a transfer learning feature extraction model using TensorFlow Hub</li> <li>Introduce the TensorBoard callback to track model training results</li> <li>Compare model results using TensorBoard</li> </ul> <h2 id=how-you-can-use-this-notebook>How you can use this notebook</h2> <p>You can read through the descriptions and the code (it should all run, except for the cells which error on purpose), but there's a better option.</p> <p>Write all of the code yourself.</p> <p>Yes. I'm serious. Create a new notebook, and rewrite each line by yourself. Investigate it, see if you can break it, why does it break?</p> <p>You don't have to write the text descriptions but writing the code yourself is a great way to get hands-on experience.</p> <p>Don't worry if you make mistakes, we all do. The way to get better and make less mistakes is to <strong>write more code</strong>.</p> <div class=highlight><pre><span></span><code><span class=c1># Add timestamp</span>
<span class=kn>import</span><span class=w> </span><span class=nn>datetime</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Notebook last run (end-to-end): </span><span class=si>{</span><span class=n>datetime</span><span class=o>.</span><span class=n>datetime</span><span class=o>.</span><span class=n>now</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>Notebook last run (end-to-end): 2024-04-20 13:58:54.678802
</code></pre></div> <h2 id=using-a-gpu>Using a GPU</h2> <p>To begin, let's check to see if we're using a GPU. Using a GPU will make sure our model trains faster than using just a CPU.</p> <div class=highlight><pre><span></span><code><span class=c1># Are we using a GPU?</span>
<span class=err>!</span><span class=n>nvidia</span><span class=o>-</span><span class=n>smi</span>
</code></pre></div> <div class=highlight><pre><span></span><code>Sat Apr 20 13:58:58 2024       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 517.48       Driver Version: 517.48       CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |
| N/A   46C    P3    12W /  N/A |      0MiB /  4096MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
</code></pre></div> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>tensorflow</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>tf</span>
</code></pre></div> <div class=highlight><pre><span></span><code>&lt;function tensorflow.python.framework.config.list_physical_devices(device_type=None)&gt;
</code></pre></div> <div class=highlight><pre><span></span><code><span class=nb>print</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>list_physical_devices</span><span class=p>(</span><span class=s2>&quot;GPU&quot;</span><span class=p>))</span>
</code></pre></div> <div class=highlight><pre><span></span><code>[]
</code></pre></div> <p>If the cell above doesn't output something which looks like:</p> <div class=highlight><pre><span></span><code>Fri Sep  4 03:35:21 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |
| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |
|                               |                      |                 ERR! |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
</code></pre></div> <p>Go to Runtime -&gt; Change Runtime Type -&gt; Hardware Accelerator and select "GPU", then rerun the cell above.</p> <h2 id=transfer-leanring-with-tensorflow-hub-getting-great-results-with-10-of-the-data>Transfer leanring with TensorFlow Hub: Getting great results with 10% of the data</h2> <p>If you've been thinking, "surely someone else has spent the time crafting the right model for the job..." then you're in luck. </p> <p>For many of the problems you'll want to use deep learning for, chances are, a working model already exists.</p> <p>And the good news is, you can access many of them on TensorFlow Hub.</p> <p><a href=https://tfhub.dev/ >TensorFlow Hub</a> is a repository for existing model components. It makes it so you can import and use a fully trained model with as little as a URL.</p> <p>Now, I really want to demonstrate the power of transfer learning to you.</p> <p>To do so, what if I told you we could get much of the same results (or better) than our best model has gotten so far with only 10% of the original data, in other words, 10x less data.</p> <p>This seems counterintuitive right?</p> <p>Wouldn't you think more examples of what a picture of food looked like led to better results?</p> <p>And you'd be right if you thought so, generally, more data leads to better results.</p> <p>However, what if you didn't have more data? What if instead of 750 images per class, you had 75 images per class?</p> <p>Collecting 675 more images of a certain class could take a long time.</p> <p>So this is where another major benefit of transfer learning comes in.</p> <p><strong>Transfer learning often allows you to get great results with less data.</strong></p> <p>But don't just take my word for it. Let's download a subset of the data we've been using, namely 10% of the training data from the <code>10_food_classes</code> dataset and use it to train a food image classifier on.</p> <p><a class=glightbox href=https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/04-transfer-learning-feature-extraction.png data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt src=https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/04-transfer-learning-feature-extraction.png></a> <em>What we're working towards building. Taking a pre-trained model and adding our own custom layers on top, extracting all of the underlying patterns learned on another dataset our own images.</em></p> <h2 id=downloading-and-becoming-one-with-the-data>Downloading and becoming one with the data</h2> <div class=highlight><pre><span></span><code><span class=c1># Get data (10% of labels)</span>
<span class=kn>import</span><span class=w> </span><span class=nn>zipfile</span>

<span class=c1># Download data</span>
<span class=err>!</span><span class=n>wget</span> <span class=n>https</span><span class=p>:</span><span class=o>//</span><span class=n>storage</span><span class=o>.</span><span class=n>googleapis</span><span class=o>.</span><span class=n>com</span><span class=o>/</span><span class=n>ztm_tf_course</span><span class=o>/</span><span class=n>food_vision</span><span class=o>/</span><span class=mi>10</span><span class=n>_food_classes_10_percent</span><span class=o>.</span><span class=n>zip</span>

<span class=c1># Unzip the downloaded file</span>
<span class=n>zip_ref</span> <span class=o>=</span> <span class=n>zipfile</span><span class=o>.</span><span class=n>ZipFile</span><span class=p>(</span><span class=s2>&quot;10_food_classes_10_percent.zip&quot;</span><span class=p>,</span> <span class=s2>&quot;r&quot;</span><span class=p>)</span>
<span class=n>zip_ref</span><span class=o>.</span><span class=n>extractall</span><span class=p>()</span>
<span class=n>zip_ref</span><span class=o>.</span><span class=n>close</span><span class=p>()</span>
</code></pre></div> <div class=highlight><pre><span></span><code>--2023-05-11 04:22:37--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip
Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.68.128, 74.125.24.128, 142.250.4.128, ...
Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.68.128|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 168546183 (161M) [application/zip]
Saving to: ‚Äò10_food_classes_10_percent.zip‚Äô

10_food_classes_10_ 100%[===================&gt;] 160.74M  19.2MB/s    in 9.7s

2023-05-11 04:22:48 (16.5 MB/s) - ‚Äò10_food_classes_10_percent.zip‚Äô saved [168546183/168546183]
</code></pre></div> <div class=highlight><pre><span></span><code><span class=c1># How many images in each folder?</span>
<span class=kn>import</span><span class=w> </span><span class=nn>os</span>

<span class=c1># Walk through 10 percent data directory and list number of files</span>
<span class=k>for</span> <span class=n>dirpath</span><span class=p>,</span> <span class=n>dirnames</span><span class=p>,</span> <span class=n>filenames</span> <span class=ow>in</span> <span class=n>os</span><span class=o>.</span><span class=n>walk</span><span class=p>(</span><span class=s2>&quot;10_food_classes_10_percent&quot;</span><span class=p>):</span>
  <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;There are </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>dirnames</span><span class=p>)</span><span class=si>}</span><span class=s2> directories and </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>filenames</span><span class=p>)</span><span class=si>}</span><span class=s2> images in &#39;</span><span class=si>{</span><span class=n>dirpath</span><span class=si>}</span><span class=s2>&#39;.&quot;</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>There are 2 directories and 0 images in &#39;10_food_classes_10_percent&#39;.
There are 10 directories and 0 images in &#39;10_food_classes_10_percent/test&#39;.
There are 0 directories and 250 images in &#39;10_food_classes_10_percent/test/chicken_wings&#39;.
There are 0 directories and 250 images in &#39;10_food_classes_10_percent/test/fried_rice&#39;.
There are 0 directories and 250 images in &#39;10_food_classes_10_percent/test/ice_cream&#39;.
There are 0 directories and 250 images in &#39;10_food_classes_10_percent/test/grilled_salmon&#39;.
There are 0 directories and 250 images in &#39;10_food_classes_10_percent/test/chicken_curry&#39;.
There are 0 directories and 250 images in &#39;10_food_classes_10_percent/test/hamburger&#39;.
There are 0 directories and 250 images in &#39;10_food_classes_10_percent/test/steak&#39;.
There are 0 directories and 250 images in &#39;10_food_classes_10_percent/test/pizza&#39;.
There are 0 directories and 250 images in &#39;10_food_classes_10_percent/test/sushi&#39;.
There are 0 directories and 250 images in &#39;10_food_classes_10_percent/test/ramen&#39;.
There are 10 directories and 0 images in &#39;10_food_classes_10_percent/train&#39;.
There are 0 directories and 75 images in &#39;10_food_classes_10_percent/train/chicken_wings&#39;.
There are 0 directories and 75 images in &#39;10_food_classes_10_percent/train/fried_rice&#39;.
There are 0 directories and 75 images in &#39;10_food_classes_10_percent/train/ice_cream&#39;.
There are 0 directories and 75 images in &#39;10_food_classes_10_percent/train/grilled_salmon&#39;.
There are 0 directories and 75 images in &#39;10_food_classes_10_percent/train/chicken_curry&#39;.
There are 0 directories and 75 images in &#39;10_food_classes_10_percent/train/hamburger&#39;.
There are 0 directories and 75 images in &#39;10_food_classes_10_percent/train/steak&#39;.
There are 0 directories and 75 images in &#39;10_food_classes_10_percent/train/pizza&#39;.
There are 0 directories and 75 images in &#39;10_food_classes_10_percent/train/sushi&#39;.
There are 0 directories and 75 images in &#39;10_food_classes_10_percent/train/ramen&#39;.
</code></pre></div> <p>Notice how each of the training directories now has 75 images rather than 750 images. This is key to demonstrating how well transfer learning can perform with less labelled images.</p> <p>The test directories still have the same amount of images. This means we'll be training on less data but evaluating our models on the same amount of test data.</p> <h2 id=creating-data-loaders-preparing-the-data>Creating data loaders (preparing the data)</h2> <p>Now we've downloaded the data, let's use the <a href=https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator><code>ImageDataGenerator</code></a> class along with the <code>flow_from_directory</code> method to load in our images.</p> <div class=highlight><pre><span></span><code><span class=c1># Setup data inputs</span>
<span class=kn>from</span><span class=w> </span><span class=nn>tensorflow.keras.preprocessing.image</span><span class=w> </span><span class=kn>import</span> <span class=n>ImageDataGenerator</span>

<span class=n>IMAGE_SHAPE</span> <span class=o>=</span> <span class=p>(</span><span class=mi>224</span><span class=p>,</span> <span class=mi>224</span><span class=p>)</span>
<span class=n>BATCH_SIZE</span> <span class=o>=</span> <span class=mi>32</span>

<span class=n>train_dir</span> <span class=o>=</span> <span class=s2>&quot;10_food_classes_10_percent/train/&quot;</span>
<span class=n>test_dir</span> <span class=o>=</span> <span class=s2>&quot;10_food_classes_10_percent/test/&quot;</span>

<span class=n>train_datagen</span> <span class=o>=</span> <span class=n>ImageDataGenerator</span><span class=p>(</span><span class=n>rescale</span><span class=o>=</span><span class=mi>1</span><span class=o>/</span><span class=mf>255.</span><span class=p>)</span>
<span class=n>test_datagen</span> <span class=o>=</span> <span class=n>ImageDataGenerator</span><span class=p>(</span><span class=n>rescale</span><span class=o>=</span><span class=mi>1</span><span class=o>/</span><span class=mf>255.</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Training images:&quot;</span><span class=p>)</span>
<span class=n>train_data_10_percent</span> <span class=o>=</span> <span class=n>train_datagen</span><span class=o>.</span><span class=n>flow_from_directory</span><span class=p>(</span><span class=n>train_dir</span><span class=p>,</span>
                                               <span class=n>target_size</span><span class=o>=</span><span class=n>IMAGE_SHAPE</span><span class=p>,</span>
                                               <span class=n>batch_size</span><span class=o>=</span><span class=n>BATCH_SIZE</span><span class=p>,</span>
                                               <span class=n>class_mode</span><span class=o>=</span><span class=s2>&quot;categorical&quot;</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Testing images:&quot;</span><span class=p>)</span>
<span class=n>test_data</span> <span class=o>=</span> <span class=n>train_datagen</span><span class=o>.</span><span class=n>flow_from_directory</span><span class=p>(</span><span class=n>test_dir</span><span class=p>,</span>
                                              <span class=n>target_size</span><span class=o>=</span><span class=n>IMAGE_SHAPE</span><span class=p>,</span>
                                              <span class=n>batch_size</span><span class=o>=</span><span class=n>BATCH_SIZE</span><span class=p>,</span>
                                              <span class=n>class_mode</span><span class=o>=</span><span class=s2>&quot;categorical&quot;</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code>Training images:
Found 750 images belonging to 10 classes.
Testing images:
Found 2500 images belonging to 10 classes.
</code></pre></div> <p>Excellent! Loading in the data we can see we've got 750 images in the training dataset belonging to 10 classes (75 per class) and 2500 images in the test set belonging to 10 classes (250 per class).</p> <h2 id=setting-up-callbacks-things-to-run-whilst-our-model-trains>Setting up callbacks (things to run whilst our model trains)</h2> <p>Before we build a model, there's an important concept we're going to get familiar with because it's going to play a key role in our future model building experiments.</p> <p>And that concept is <strong>callbacks</strong>.</p> <p><a href=https://www.tensorflow.org/api_docs/python/tf/keras/callbacks>Callbacks</a> are extra functionality you can add to your models to be performed during or after training. Some of the most popular callbacks include: * <a href=https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard><strong>Experiment tracking with TensorBoard</strong></a> - log the performance of multiple models and then view and compare these models in a visual way on <a href=https://www.tensorflow.org/tensorboard>TensorBoard</a> (a dashboard for inspecting neural network parameters). Helpful to compare the results of different models on your data. * <a href=https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint><strong>Model checkpointing</strong></a> - save your model as it trains so you can stop training if needed and come back to continue off where you left. Helpful if training takes a long time and can't be done in one sitting. * <a href=https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping><strong>Early stopping</strong></a> - leave your model training for an arbitrary amount of time and have it stop training automatically when it ceases to improve. Helpful when you've got a large dataset and don't know how long training will take.</p> <p>We'll explore each of these overtime but for this notebook, we'll see how the TensorBoard callback can be used.</p> <p>The TensorBoard callback can be accessed using <a href=https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard><code>tf.keras.callbacks.TensorBoard()</code></a>. </p> <p>Its main functionality is saving a model's training performance metrics to a specified <code>log_dir</code>.</p> <p>By default, logs are recorded every epoch using the <code>update_freq='epoch'</code> parameter. This is a good default since tracking model performance too often can slow down model training.</p> <p>To track our modelling experiments using TensorBoard, let's create a function which creates a TensorBoard callback for us.</p> <blockquote> <p>üîë <strong>Note:</strong> We create a function for creating a TensorBoard callback because as we'll see later on, each model needs its own TensorBoard callback instance (so the function will create a new one each time it's run).</p> </blockquote> <div class=highlight><pre><span></span><code><span class=c1># Create tensorboard callback (functionized because need to create a new one for each model)</span>
<span class=kn>import</span><span class=w> </span><span class=nn>datetime</span>
<span class=k>def</span><span class=w> </span><span class=nf>create_tensorboard_callback</span><span class=p>(</span><span class=n>dir_name</span><span class=p>,</span> <span class=n>experiment_name</span><span class=p>):</span>
  <span class=n>log_dir</span> <span class=o>=</span> <span class=n>dir_name</span> <span class=o>+</span> <span class=s2>&quot;/&quot;</span> <span class=o>+</span> <span class=n>experiment_name</span> <span class=o>+</span> <span class=s2>&quot;/&quot;</span> <span class=o>+</span> <span class=n>datetime</span><span class=o>.</span><span class=n>datetime</span><span class=o>.</span><span class=n>now</span><span class=p>()</span><span class=o>.</span><span class=n>strftime</span><span class=p>(</span><span class=s2>&quot;%Y%m</span><span class=si>%d</span><span class=s2>-%H%M%S&quot;</span><span class=p>)</span>
  <span class=n>tensorboard_callback</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>callbacks</span><span class=o>.</span><span class=n>TensorBoard</span><span class=p>(</span>
      <span class=n>log_dir</span><span class=o>=</span><span class=n>log_dir</span>
  <span class=p>)</span>
  <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Saving TensorBoard log files to: </span><span class=si>{</span><span class=n>log_dir</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
  <span class=k>return</span> <span class=n>tensorboard_callback</span>
</code></pre></div> <p>Because you're likely to run multiple experiments, it's a good idea to be able to track them in some way.</p> <p>In our case, our function saves a model's performance logs to a directory named <code>[dir_name]/[experiment_name]/[current_timestamp]</code>, where: * <code>dir_name</code> is the overall logs directory * <code>experiment_name</code> is the particular experiment * <code>current_timestamp</code> is the time the experiment started based on Python's <a href=https://docs.python.org/3/library/datetime.html#datetime.datetime.now><code>datetime.datetime().now()</code></a></p> <blockquote> <p>üîë <strong>Note:</strong> Depending on your use case, the above experimenting tracking naming method may work or you might require something more specific. The good news is, the TensorBoard callback makes it easy to track modelling logs as long as you specify where to track them. So you can get as creative as you like with how you name your experiments, just make sure you or your team can understand them.</p> </blockquote> <h2 id=creating-models-using-tensorflow-hub>Creating models using TensorFlow Hub</h2> <p>In the past we've used TensorFlow to create our own models layer by layer from scratch.</p> <p>Now we're going to do a similar process, except the majority of our model's layers are going to come from <a href=https://tfhub.dev/ >TensorFlow Hub</a>.</p> <p>In fact, we're going to use two models from TensorFlow Hub: 1. <a href=https://arxiv.org/abs/1603.05027>ResNetV2</a> - a state of the art computer vision model architecture from 2016. 2. <a href=https://arxiv.org/abs/1905.11946>EfficientNet</a> - a state of the art computer vision architecture from 2019.</p> <p>State of the art means that at some point, both of these models have achieved the lowest error rate on <a href=http://www.image-net.org/ >ImageNet (ILSVRC-2012-CLS)</a>, the gold standard of computer vision benchmarks.</p> <p>You might be wondering, how do you find these models on TensorFlow Hub?</p> <p>Here are the steps I took:</p> <ol> <li>Go to <a href=https://tfhub.dev/ >tfhub.dev</a>.</li> <li>Choose your problem domain, e.g. "Image" (we're using food images).</li> <li>Select your TF version, which in our case is TF2.</li> <li>Remove all "Problem domanin" filters except for the problem you're working on. </li> <li><strong>Note:</strong> "Image feature vector" can be used alongside almost any problem, we'll get to this soon.</li> <li>The models listed are all models which could potentially be used for your problem.</li> </ol> <blockquote> <p>ü§î <strong>Question:</strong> <em>I see many options for image classification models, how do I know which is best?</em></p> </blockquote> <p>You can see a list of state of the art models on <a href=https://www.paperswithcode.com>paperswithcode.com</a>, a resource for collecting the latest in deep learning paper results which have code implementations for the findings they report.</p> <p>Since we're working with images, our target are the <a href=https://paperswithcode.com/sota/image-classification-on-imagenet>models which perform best on ImageNet</a>.</p> <p>You'll probably find not all of the model architectures listed on paperswithcode appear on TensorFlow Hub. And this is okay, we can still use what's available.</p> <p>To find our models, let's narrow down our search using the Architecture tab.</p> <ol> <li>Select the Architecture tab on TensorFlow Hub and you'll see a dropdown menu of architecture names appear. </li> <li>The rule of thumb here is generally, names with larger numbers means better performing models. For example, EfficientNetB4 performs better than EfficientNetB0.<ul> <li>However, the tradeoff with larger numbers can mean they take longer to compute. </li> </ul> </li> <li>Select EfficientNetB0 and you should see <a href="https://tfhub.dev/s?module-type=image-classification,image-feature-vector&network-architecture=efficientnet-b0&tf-version=tf2">something like the following</a>: <a class=glightbox href=https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/04-tensorflow-hub-efficientnetb0.png data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt src=https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/04-tensorflow-hub-efficientnetb0.png></a></li> <li>Clicking the one titled "<a href=https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1>efficientnet/b0/feature-vector</a>" brings us to a page with a button that says "Copy URL". That URL is what we can use to harness the power of EfficientNetB0.</li> <li>Copying the URL should give you something like this: https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1</li> </ol> <blockquote> <p>ü§î <strong>Question:</strong> <em>I thought we were doing image classification, why do we choose feature vector and not classification?</em></p> </blockquote> <p>Great observation. This is where the differnet types of transfer learning come into play, as is, feature extraction and fine-tuning.</p> <ol> <li> <p><strong>"As is" transfer learning</strong> is when you take a pretrained model as it is and apply it to your task without any changes. </p> </li> <li> <p>For example, many computer vision models are pretrained on the ImageNet dataset which contains 1000 different classes of images. This means passing a single image to this model will produce 1000 different prediction probability values (1 for each class). </p> <ul> <li>This is helpful if you have 1000 classes of image you'd like to classify and they're all the same as the ImageNet classes, however, it's not helpful if you want to classify only a small subset of classes (such as 10 different kinds of food). Model's with <code>"/classification"</code> in their name on TensorFlow Hub provide this kind of functionality.</li> </ul> </li> <li> <p><strong>Feature extraction transfer learning</strong> is when you take the underlying patterns (also called weights) a pretrained model has learned and adjust its outputs to be more suited to your problem. </p> </li> <li> <p>For example, say the pretrained model you were using had 236 different layers (EfficientNetB0 has 236 layers), but the top layer outputs 1000 classes because it was pretrained on ImageNet. To adjust this to your own problem, you might remove the original activation layer and replace it with your own but with the right number of output classes. The important part here is that <strong>only the top few layers become trainable, the rest remain frozen</strong>. </p> <ul> <li>This way all the underlying patterns remain in the rest of the layers and you can utilise them for your own problem. This kind of transfer learning is very helpful when your data is similar to the data a model has been pretrained on.</li> </ul> </li> <li> <p><strong>Fine-tuning transfer learning</strong> is when you take the underlying patterns (also called weights) of a pretrained model and adjust (fine-tune) them to your own problem. </p> <ul> <li>This usually means training <strong>some, many or all</strong> of the layers in the pretrained model. This is useful when you've got a large dataset (e.g. 100+ images per class) where your data is slightly different to the data the original model was trained on.</li> </ul> </li> </ol> <p>A common workflow is to "freeze" all of the learned patterns in the bottom layers of a pretrained model so they're untrainable. And then train the top 2-3 layers of so the pretrained model can adjust its outputs to your custom data (<strong>feature extraction</strong>).</p> <p>After you've trained the top 2-3 layers, you can then gradually "unfreeze" more and more layers and run the training process on your own data to further <strong>fine-tune</strong> the pretrained model.</p> <blockquote> <p>ü§î <strong>Question:</strong> <em>Why train only the top 2-3 layers in feature extraction?</em></p> </blockquote> <p>The lower a layer is in a computer vision model as in, the closer it is to the input layer, the larger the features it learn. For example, a bottom layer in a computer vision model to identify images of cats or dogs might learn the outline of legs, where as, layers closer to the output might learn the shape of teeth. Often, you'll want the larger features (learned patterns are also called features) to remain, since these are similar for both animals, where as, the differences remain in the more fine-grained features.</p> <p><a class=glightbox href=https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/04-different-kinds-of-transfer-learning.png data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt src=https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/04-different-kinds-of-transfer-learning.png></a> <em>The different kinds of transfer learning. An original model, a feature extraction model (only top 2-3 layers change) and a fine-tuning model (many or all of original model get changed).</em></p> <p>Okay, enough talk, let's see this in action. Once we do, we'll explain what's happening.</p> <p>First we'll import TensorFlow and TensorFlow Hub.</p> <div class=highlight><pre><span></span><code><span class=kn>import</span><span class=w> </span><span class=nn>tensorflow</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>tf</span>
<span class=kn>import</span><span class=w> </span><span class=nn>tensorflow_hub</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>hub</span>
<span class=kn>from</span><span class=w> </span><span class=nn>tensorflow.keras</span><span class=w> </span><span class=kn>import</span> <span class=n>layers</span>
</code></pre></div> <p>Now we'll get the feature vector URLs of two common computer vision architectures, <a href=https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1>EfficientNetB0 (2019)</a> and <a href=https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4>ResNetV250 (2016)</a> from TensorFlow Hub using the steps above.</p> <p>We're getting both of these because we're going to compare them to see which performs better on our data.</p> <blockquote> <p>üîë <strong>Note:</strong> Comparing different model architecture performance on the same data is a very common practice. The simple reason is because you want to know which model performs best for your problem.</p> <p><strong>Update:</strong> As of 14 August 2021, <a href=https://tfhub.dev/google/collections/efficientnet_v2/1>EfficientNet V2 pretrained models are available on TensorFlow Hub</a>. The original code in this notebook uses EfficientNet V1, it has been left unchanged. In <a href=https://github.com/mrdbourke/tensorflow-deep-learning/discussions/166>my experiments with this dataset</a>, V1 outperforms V2. Best to experiment with your own data and see what suits you.</p> </blockquote> <div class=highlight><pre><span></span><code><span class=c1># Resnet 50 V2 feature vector</span>
<span class=n>resnet_url</span> <span class=o>=</span> <span class=s2>&quot;https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4&quot;</span>

<span class=c1># Original: EfficientNetB0 feature vector (version 1)</span>
<span class=n>efficientnet_url</span> <span class=o>=</span> <span class=s2>&quot;https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1&quot;</span>

<span class=c1># # New: EfficientNetB0 feature vector (version 2)</span>
<span class=c1># efficientnet_url = &quot;https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2&quot;</span>
</code></pre></div> <p>These URLs link to a saved pretrained model on TensorFlow Hub.</p> <p>When we use them in our model, the model will automatically be downloaded for us to use.</p> <p>To do this, we can use the <a href=https://www.tensorflow.org/hub/api_docs/python/hub/KerasLayer><code>KerasLayer()</code></a> model inside the TensorFlow hub library.</p> <p>Since we're going to be comparing two models, to save ourselves code, we'll create a function <code>create_model()</code>. This function will take a model's TensorFlow Hub URL, instatiate a Keras Sequential model with the appropriate number of output layers and return the model.</p> <div class=highlight><pre><span></span><code><span class=k>def</span><span class=w> </span><span class=nf>create_model</span><span class=p>(</span><span class=n>model_url</span><span class=p>,</span> <span class=n>num_classes</span><span class=o>=</span><span class=mi>10</span><span class=p>):</span>
<span class=w>  </span><span class=sd>&quot;&quot;&quot;Takes a TensorFlow Hub URL and creates a Keras Sequential model with it.</span>

<span class=sd>  Args:</span>
<span class=sd>    model_url (str): A TensorFlow Hub feature extraction URL.</span>
<span class=sd>    num_classes (int): Number of output neurons in output layer,</span>
<span class=sd>      should be equal to number of target classes, default 10.</span>

<span class=sd>  Returns:</span>
<span class=sd>    An uncompiled Keras Sequential model with model_url as feature</span>
<span class=sd>    extractor layer and Dense output layer with num_classes outputs.</span>
<span class=sd>  &quot;&quot;&quot;</span>
  <span class=c1># Download the pretrained model and save it as a Keras layer</span>
  <span class=n>feature_extractor_layer</span> <span class=o>=</span> <span class=n>hub</span><span class=o>.</span><span class=n>KerasLayer</span><span class=p>(</span><span class=n>model_url</span><span class=p>,</span>
                                           <span class=n>trainable</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=c1># freeze the underlying patterns</span>
                                           <span class=n>name</span><span class=o>=</span><span class=s1>&#39;feature_extraction_layer&#39;</span><span class=p>,</span>
                                           <span class=n>input_shape</span><span class=o>=</span><span class=n>IMAGE_SHAPE</span><span class=o>+</span><span class=p>(</span><span class=mi>3</span><span class=p>,))</span> <span class=c1># define the input image shape</span>

  <span class=c1># Create our own model</span>
  <span class=n>model</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>Sequential</span><span class=p>([</span>
    <span class=n>feature_extractor_layer</span><span class=p>,</span> <span class=c1># use the feature extraction layer as the base</span>
    <span class=n>layers</span><span class=o>.</span><span class=n>Dense</span><span class=p>(</span><span class=n>num_classes</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;softmax&#39;</span><span class=p>,</span> <span class=n>name</span><span class=o>=</span><span class=s1>&#39;output_layer&#39;</span><span class=p>)</span> <span class=c1># create our own output layer      </span>
  <span class=p>])</span>

  <span class=k>return</span> <span class=n>model</span>
</code></pre></div> <p>Great! Now we've got a function for creating a model, we'll use it to first create a model using the ResNetV250 architecture as our feature extraction layer.</p> <p>Once the model is instantiated, we'll compile it using <code>categorical_crossentropy</code> as our loss function, the Adam optimizer and accuracy as our metric.</p> <div class=highlight><pre><span></span><code><span class=c1># Create model</span>
<span class=n>resnet_model</span> <span class=o>=</span> <span class=n>create_model</span><span class=p>(</span><span class=n>resnet_url</span><span class=p>,</span> <span class=n>num_classes</span><span class=o>=</span><span class=n>train_data_10_percent</span><span class=o>.</span><span class=n>num_classes</span><span class=p>)</span>

<span class=c1># Compile</span>
<span class=n>resnet_model</span><span class=o>.</span><span class=n>compile</span><span class=p>(</span><span class=n>loss</span><span class=o>=</span><span class=s1>&#39;categorical_crossentropy&#39;</span><span class=p>,</span>
                     <span class=n>optimizer</span><span class=o>=</span><span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>optimizers</span><span class=o>.</span><span class=n>Adam</span><span class=p>(),</span>
                     <span class=n>metrics</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;accuracy&#39;</span><span class=p>])</span>
</code></pre></div> <p><a class=glightbox href=https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/04-resnet-feature-extractor.png data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt src=https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/04-resnet-feature-extractor.png></a> <em>What our current model looks like. A ResNet50V2 backbone with a custom dense layer on top (10 classes instead of 1000 ImageNet classes). </em><em>Note:</em><em> The Image shows ResNet34 instead of ResNet50. </em><em>Image source:</em><em> https://arxiv.org/abs/1512.03385.</em></p> <p>Beautiful. Time to fit the model.</p> <p>We've got the training data ready in <code>train_data_10_percent</code> as well as the test data saved as <code>test_data</code>.</p> <p>But before we call the fit function, there's one more thing we're going to add, a callback. More specifically, a TensorBoard callback so we can track the performance of our model on TensorBoard.</p> <p>We can add a callback to our model by using the <code>callbacks</code> parameter in the fit function.</p> <p>In our case, we'll pass the <code>callbacks</code> parameter the <code>create_tensorboard_callback()</code> we created earlier with some specific inputs so we know what experiments we're running.</p> <p>Let's keep this experiment short and train for 5 epochs.</p> <div class=highlight><pre><span></span><code><span class=c1># Fit the model</span>
<span class=n>resnet_history</span> <span class=o>=</span> <span class=n>resnet_model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>train_data_10_percent</span><span class=p>,</span>
                                  <span class=n>epochs</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span>
                                  <span class=n>steps_per_epoch</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=n>train_data_10_percent</span><span class=p>),</span>
                                  <span class=n>validation_data</span><span class=o>=</span><span class=n>test_data</span><span class=p>,</span>
                                  <span class=n>validation_steps</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=n>test_data</span><span class=p>),</span>
                                  <span class=c1># Add TensorBoard callback to model (callbacks parameter takes a list)</span>
                                  <span class=n>callbacks</span><span class=o>=</span><span class=p>[</span><span class=n>create_tensorboard_callback</span><span class=p>(</span><span class=n>dir_name</span><span class=o>=</span><span class=s2>&quot;tensorflow_hub&quot;</span><span class=p>,</span> <span class=c1># save experiment logs here</span>
                                                                         <span class=n>experiment_name</span><span class=o>=</span><span class=s2>&quot;resnet50V2&quot;</span><span class=p>)])</span> <span class=c1># name of log files</span>
</code></pre></div> <div class=highlight><pre><span></span><code>Saving TensorBoard log files to: tensorflow_hub/resnet50V2/20230511-042304
Epoch 1/5
24/24 [==============================] - 28s 680ms/step - loss: 1.7915 - accuracy: 0.3880 - val_loss: 1.1463 - val_accuracy: 0.6368
Epoch 2/5
24/24 [==============================] - 14s 620ms/step - loss: 0.8710 - accuracy: 0.7560 - val_loss: 0.8359 - val_accuracy: 0.7352
Epoch 3/5
24/24 [==============================] - 14s 618ms/step - loss: 0.6160 - accuracy: 0.8373 - val_loss: 0.7385 - val_accuracy: 0.7676
Epoch 4/5
24/24 [==============================] - 15s 624ms/step - loss: 0.4705 - accuracy: 0.8907 - val_loss: 0.7016 - val_accuracy: 0.7728
Epoch 5/5
24/24 [==============================] - 15s 640ms/step - loss: 0.3744 - accuracy: 0.9200 - val_loss: 0.6764 - val_accuracy: 0.7772
</code></pre></div> <p>Wow! </p> <p>It seems that after only 5 epochs, the ResNetV250 feature extraction model was able to blow any of the architectures we made out of the water, achieving around 90% accuracy on the training set and nearly 80% accuracy on the test set...<strong>with only 10 percent of the training images!</strong></p> <p>That goes to show the power of transfer learning. And it's one of the main reasons whenever you're trying to model your own datasets, you should look into what pretrained models already exist.</p> <p>Let's check out our model's training curves using our <code>plot_loss_curves</code> function.</p> <div class=highlight><pre><span></span><code><span class=c1># If you wanted to, you could really turn this into a helper function to load in with a helper.py script...</span>
<span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>

<span class=c1># Plot the validation and training data separately</span>
<span class=k>def</span><span class=w> </span><span class=nf>plot_loss_curves</span><span class=p>(</span><span class=n>history</span><span class=p>):</span>
<span class=w>  </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>  Returns separate loss curves for training and validation metrics.</span>
<span class=sd>  &quot;&quot;&quot;</span> 
  <span class=n>loss</span> <span class=o>=</span> <span class=n>history</span><span class=o>.</span><span class=n>history</span><span class=p>[</span><span class=s1>&#39;loss&#39;</span><span class=p>]</span>
  <span class=n>val_loss</span> <span class=o>=</span> <span class=n>history</span><span class=o>.</span><span class=n>history</span><span class=p>[</span><span class=s1>&#39;val_loss&#39;</span><span class=p>]</span>

  <span class=n>accuracy</span> <span class=o>=</span> <span class=n>history</span><span class=o>.</span><span class=n>history</span><span class=p>[</span><span class=s1>&#39;accuracy&#39;</span><span class=p>]</span>
  <span class=n>val_accuracy</span> <span class=o>=</span> <span class=n>history</span><span class=o>.</span><span class=n>history</span><span class=p>[</span><span class=s1>&#39;val_accuracy&#39;</span><span class=p>]</span>

  <span class=n>epochs</span> <span class=o>=</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>history</span><span class=o>.</span><span class=n>history</span><span class=p>[</span><span class=s1>&#39;loss&#39;</span><span class=p>]))</span>

  <span class=c1># Plot loss</span>
  <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>epochs</span><span class=p>,</span> <span class=n>loss</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;training_loss&#39;</span><span class=p>)</span>
  <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>epochs</span><span class=p>,</span> <span class=n>val_loss</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;val_loss&#39;</span><span class=p>)</span>
  <span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Loss&#39;</span><span class=p>)</span>
  <span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Epochs&#39;</span><span class=p>)</span>
  <span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>()</span>

  <span class=c1># Plot accuracy</span>
  <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>()</span>
  <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>epochs</span><span class=p>,</span> <span class=n>accuracy</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;training_accuracy&#39;</span><span class=p>)</span>
  <span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>epochs</span><span class=p>,</span> <span class=n>val_accuracy</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s1>&#39;val_accuracy&#39;</span><span class=p>)</span>
  <span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;Accuracy&#39;</span><span class=p>)</span>
  <span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Epochs&#39;</span><span class=p>)</span>
  <span class=n>plt</span><span class=o>.</span><span class=n>legend</span><span class=p>();</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>plot_loss_curves</span><span class=p>(</span><span class=n>resnet_history</span><span class=p>)</span>
</code></pre></div> <p><a class=glightbox href=../04_transfer_learning_in_tensorflow_part_1_feature_extraction_files/04_transfer_learning_in_tensorflow_part_1_feature_extraction_31_0.png data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt=png src=../04_transfer_learning_in_tensorflow_part_1_feature_extraction_files/04_transfer_learning_in_tensorflow_part_1_feature_extraction_31_0.png></a></p> <p><a class=glightbox href=../04_transfer_learning_in_tensorflow_part_1_feature_extraction_files/04_transfer_learning_in_tensorflow_part_1_feature_extraction_31_1.png data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt=png src=../04_transfer_learning_in_tensorflow_part_1_feature_extraction_files/04_transfer_learning_in_tensorflow_part_1_feature_extraction_31_1.png></a></p> <p>And what about a summary of our model?</p> <div class=highlight><pre><span></span><code><span class=c1># Resnet summary </span>
<span class=n>resnet_model</span><span class=o>.</span><span class=n>summary</span><span class=p>()</span>
</code></pre></div> <div class=highlight><pre><span></span><code>Model: &quot;sequential&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 feature_extraction_layer (K  (None, 2048)             23564800  
 erasLayer)

 output_layer (Dense)        (None, 10)                20490

=================================================================
Total params: 23,585,290
Trainable params: 20,490
Non-trainable params: 23,564,800
_________________________________________________________________
</code></pre></div> <p>You can see the power of TensorFlow Hub here. The feature extraction layer has 23,564,800 parameters which are prelearned patterns the model has already learned on the ImageNet dataset. Since we set <code>trainable=False</code>, these patterns remain frozen (non-trainable) during training.</p> <p>This means during training the model updates the 20,490 parameters in the output layer to suit our dataset.</p> <p>Okay, we've trained a ResNetV250 model, time to do the same with EfficientNetB0 model.</p> <p>The setup will be the exact same as before, except for the <code>model_url</code> parameter in the <code>create_model()</code> function and the <code>experiment_name</code> parameter in the <code>create_tensorboard_callback()</code> function.</p> <div class=highlight><pre><span></span><code><span class=c1># Create model</span>
<span class=n>efficientnet_model</span> <span class=o>=</span> <span class=n>create_model</span><span class=p>(</span><span class=n>model_url</span><span class=o>=</span><span class=n>efficientnet_url</span><span class=p>,</span> <span class=c1># use EfficientNetB0 TensorFlow Hub URL</span>
                                  <span class=n>num_classes</span><span class=o>=</span><span class=n>train_data_10_percent</span><span class=o>.</span><span class=n>num_classes</span><span class=p>)</span>

<span class=c1># Compile EfficientNet model</span>
<span class=n>efficientnet_model</span><span class=o>.</span><span class=n>compile</span><span class=p>(</span><span class=n>loss</span><span class=o>=</span><span class=s1>&#39;categorical_crossentropy&#39;</span><span class=p>,</span>
                           <span class=n>optimizer</span><span class=o>=</span><span class=n>tf</span><span class=o>.</span><span class=n>keras</span><span class=o>.</span><span class=n>optimizers</span><span class=o>.</span><span class=n>Adam</span><span class=p>(),</span>
                           <span class=n>metrics</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;accuracy&#39;</span><span class=p>])</span>

<span class=c1># Fit EfficientNet model </span>
<span class=n>efficientnet_history</span> <span class=o>=</span> <span class=n>efficientnet_model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>train_data_10_percent</span><span class=p>,</span> <span class=c1># only use 10% of training data</span>
                                              <span class=n>epochs</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=c1># train for 5 epochs</span>
                                              <span class=n>steps_per_epoch</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=n>train_data_10_percent</span><span class=p>),</span>
                                              <span class=n>validation_data</span><span class=o>=</span><span class=n>test_data</span><span class=p>,</span>
                                              <span class=n>validation_steps</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=n>test_data</span><span class=p>),</span>
                                              <span class=n>callbacks</span><span class=o>=</span><span class=p>[</span><span class=n>create_tensorboard_callback</span><span class=p>(</span><span class=n>dir_name</span><span class=o>=</span><span class=s2>&quot;tensorflow_hub&quot;</span><span class=p>,</span> 
                                                                                     <span class=c1># Track logs under different experiment name</span>
                                                                                     <span class=n>experiment_name</span><span class=o>=</span><span class=s2>&quot;efficientnetB0&quot;</span><span class=p>)])</span>
</code></pre></div> <div class=highlight><pre><span></span><code>Saving TensorBoard log files to: tensorflow_hub/efficientnetB0/20230511-042443
Epoch 1/5
24/24 [==============================] - 26s 693ms/step - loss: 1.7622 - accuracy: 0.5053 - val_loss: 1.2434 - val_accuracy: 0.7268
Epoch 2/5
24/24 [==============================] - 15s 634ms/step - loss: 1.0120 - accuracy: 0.7693 - val_loss: 0.8459 - val_accuracy: 0.8240
Epoch 3/5
24/24 [==============================] - 15s 642ms/step - loss: 0.7289 - accuracy: 0.8347 - val_loss: 0.6823 - val_accuracy: 0.8460
Epoch 4/5
24/24 [==============================] - 15s 637ms/step - loss: 0.5871 - accuracy: 0.8667 - val_loss: 0.6004 - val_accuracy: 0.8592
Epoch 5/5
24/24 [==============================] - 14s 620ms/step - loss: 0.5013 - accuracy: 0.8947 - val_loss: 0.5504 - val_accuracy: 0.8636
</code></pre></div> <p>Holy smokes! The EfficientNetB0 model does even better than the ResNetV250 model! Achieving over 85% accuracy on the test set...again <strong>with only 10% of the training data</strong>.</p> <p>How cool is that?</p> <p>With a couple of lines of code we're able to leverage state of the art models and adjust them to our own use case.</p> <p>Let's check out the loss curves.</p> <div class=highlight><pre><span></span><code><span class=n>plot_loss_curves</span><span class=p>(</span><span class=n>efficientnet_history</span><span class=p>)</span>
</code></pre></div> <p><a class=glightbox href=../04_transfer_learning_in_tensorflow_part_1_feature_extraction_files/04_transfer_learning_in_tensorflow_part_1_feature_extraction_37_0.png data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt=png src=../04_transfer_learning_in_tensorflow_part_1_feature_extraction_files/04_transfer_learning_in_tensorflow_part_1_feature_extraction_37_0.png></a></p> <p><a class=glightbox href=../04_transfer_learning_in_tensorflow_part_1_feature_extraction_files/04_transfer_learning_in_tensorflow_part_1_feature_extraction_37_1.png data-type=image data-width=auto data-height=auto data-desc-position=bottom><img alt=png src=../04_transfer_learning_in_tensorflow_part_1_feature_extraction_files/04_transfer_learning_in_tensorflow_part_1_feature_extraction_37_1.png></a></p> <p>From the look of the EfficientNetB0 model's loss curves, it looks like if we kept training our model for longer, it might improve even further. Perhaps that's something you might want to try?</p> <p>Let's check out the model summary.</p> <div class=highlight><pre><span></span><code><span class=n>efficientnet_model</span><span class=o>.</span><span class=n>summary</span><span class=p>()</span>
</code></pre></div> <div class=highlight><pre><span></span><code>Model: &quot;sequential_1&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 feature_extraction_layer (K  (None, 1280)             4049564   
 erasLayer)

 output_layer (Dense)        (None, 10)                12810

=================================================================
Total params: 4,062,374
Trainable params: 12,810
Non-trainable params: 4,049,564
_________________________________________________________________
</code></pre></div> <p>It seems despite having over four times less parameters (4,049,564 vs. 23,564,800) than the ResNet50V2 extraction layer, the EfficientNetB0 feature extraction layer yields better performance. Now it's clear where the "efficient" name came from.</p> <h2 id=comparing-models-using-tensorboard>Comparing models using TensorBoard</h2> <p>Alright, even though we've already compared the performance of our two models by looking at the accuracy scores. But what if you had more than two models? </p> <p>That's where an experiment tracking tool like <a href=https://www.tensorflow.org/tensorboard>TensorBoard</a> (preinstalled in Google Colab) comes in.</p> <p>The good thing is, since we set up a TensorBoard callback, all of our model's training logs have been saved automatically. To visualize them, we can upload the results to <a href=https://tensorboard.dev/ >TensorBoard.dev</a>.</p> <p>Uploading your results to TensorBoard.dev enables you to track and share multiple different modelling experiments. So if you needed to show someone your results, you could send them a link to your TensorBoard.dev as well as the accompanying Colab notebook.</p> <blockquote> <p>üîë <strong>Note:</strong> These experiments are public, do not upload sensitive data. You can delete experiments if needed.</p> </blockquote> <h3 id=uploading-experiments-to-tensorboard>Uploading experiments to TensorBoard</h3> <p>To upload a series of TensorFlow logs to TensorBoard, we can use the following command:</p> <div class=highlight><pre><span></span><code>Upload TensorBoard dev records

!tensorboard dev upload --logdir ./tensorflow_hub/ \
  --name &quot;EfficientNetB0 vs. ResNet50V2&quot; \ 
  --description &quot;Comparing two different TF Hub feature extraction models architectures using 10% of training images&quot; \ 
  --one_shot
</code></pre></div> <p>Where: * <code>--logdir</code> is the target upload directory * <code>--name</code> is the name of the experiment * <code>--description</code> is a brief description of the experiment * <code>--one_shot</code> exits the TensorBoard uploader once uploading is finished</p> <p>Running the <code>tensorboard dev upload</code> command will first ask you to authorize the upload to TensorBoard.dev. After you've authorized the upload, your log files will be uploaded.</p> <div class=highlight><pre><span></span><code><span class=c1># Upload TensorBoard dev records</span>
<span class=err>!</span><span class=n>tensorboard</span> <span class=n>dev</span> <span class=n>upload</span> <span class=o>--</span><span class=n>logdir</span> <span class=o>./</span><span class=n>tensorflow_hub</span><span class=o>/</span> \
  <span class=o>--</span><span class=n>name</span> <span class=s2>&quot;EfficientNetB0 vs. ResNet50V2&quot;</span> \
  <span class=o>--</span><span class=n>description</span> <span class=s2>&quot;Comparing two different TF Hub feature extraction models architectures using 10</span><span class=si>% o</span><span class=s2>f training images&quot;</span> \
  <span class=o>--</span><span class=n>one_shot</span>
</code></pre></div> <div class=highlight><pre><span></span><code>2023-05-11 04:26:10.912881: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT

***** TensorBoard Uploader *****

This will upload your TensorBoard logs to https://tensorboard.dev/ from
the following directory:

./tensorflow_hub/

This TensorBoard will be visible to everyone. Do not upload sensitive
data.

Your use of this service is subject to Google&#39;s Terms of Service
&lt;https://policies.google.com/terms&gt; and Privacy Policy
&lt;https://policies.google.com/privacy&gt;, and TensorBoard.dev&#39;s Terms of Service
&lt;https://tensorboard.dev/policy/terms/&gt;.

This notice will not be shown again while you are logged into the uploader.
To log out, run `tensorboard dev auth revoke`.

Continue? (yes/NO) yes

To sign in with the TensorBoard uploader:

1. On your computer or phone, visit:

   https://www.google.com/device

2. Sign in with your Google account, then enter:

   PCB-DVW-YTS



New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/dIzMI7IkT7OHD1PmA4mMRQ/

[1m[2023-05-11T04:41:27][0m Started scanning logdir.
[1m[2023-05-11T04:41:32][0m Total uploaded: 60 scalars, 0 tensors, 2 binary objects (5.7 MB)
[1m[2023-05-11T04:41:32][0m Done scanning logdir.


Done. View your TensorBoard at https://tensorboard.dev/experiment/dIzMI7IkT7OHD1PmA4mMRQ/
</code></pre></div> <p>Every time you upload something to TensorBoad.dev you'll get a new experiment ID. The experiment ID will look something like this: https://tensorboard.dev/experiment/73taSKxXQeGPQsNBcVvY3g/ (this is the actual experiment from this notebook).</p> <p>If you upload the same directory again, you'll get a new experiment ID to go along with it.</p> <p>This means to track your experiments, you may want to look into how you name your uploads. That way when you find them on TensorBoard.dev you can tell what happened during each experiment (e.g. "efficientnet0_10_percent_data").</p> <h3 id=listing-experiments-youve-saved-to-tensorboard>Listing experiments you've saved to TensorBoard</h3> <p>To see all of the experiments you've uploaded you can use the command:</p> <p><code>tensorboard dev list</code></p> <div class=highlight><pre><span></span><code><span class=c1># Check out experiments</span>
<span class=c1># !tensorboard dev list # uncomment to see</span>
</code></pre></div> <h3 id=deleting-experiments-from-tensorboard>Deleting experiments from TensorBoard</h3> <p>Remember, all uploads to TensorBoard.dev are public, so to delete an experiment you can use the command:</p> <p><code>tensorboard dev delete --experiment_id [INSERT_EXPERIMENT_ID]</code></p> <div class=highlight><pre><span></span><code><span class=c1># Delete an experiment</span>
<span class=err>!</span><span class=n>tensorboard</span> <span class=n>dev</span> <span class=n>delete</span> <span class=o>--</span><span class=n>experiment_id</span> <span class=n>n6kd8XZ3Rdy1jSgSLH5WjA</span>
</code></pre></div> <div class=highlight><pre><span></span><code>2023-05-11 04:41:41.121171: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
No such experiment n6kd8XZ3Rdy1jSgSLH5WjA. Either it never existed or it has already been deleted.
</code></pre></div> <div class=highlight><pre><span></span><code><span class=c1># Check to see if experiments still exist</span>
<span class=c1># !tensorboard dev list # uncomment to see</span>
</code></pre></div> <h2 id=exercises>üõ† Exercises</h2> <ol> <li>Build and fit a model using the same data we have here but with the MobileNetV2 architecture feature extraction (<a href=https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4><code>mobilenet_v2_100_224/feature_vector</code></a>) from TensorFlow Hub, how does it perform compared to our other models?</li> <li>Name 3 different image classification models on TensorFlow Hub that we haven't used.</li> <li>Build a model to classify images of two different things you've taken photos of.</li> <li>You can use any feature extraction layer from TensorFlow Hub you like for this.</li> <li>You should aim to have at least 10 images of each class, for example to build a fridge versus oven classifier, you'll want 10 images of fridges and 10 images of ovens.</li> <li>What is the current best performing model on ImageNet?</li> <li>Hint: you might want to check <a href=https://www.sotabench.com>sotabench.com</a> for this.</li> </ol> <h2 id=extra-curriculum>üìñ Extra-curriculum</h2> <ul> <li>Read through the <a href=https://www.tensorflow.org/tutorials/images/transfer_learning>TensorFlow Transfer Learning Guide</a> and define the main two types of transfer learning in your own words.</li> <li>Go through the <a href=https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub>Transfer Learning with TensorFlow Hub tutorial</a> on the TensorFlow website and rewrite all of the code yourself into a new Google Colab notebook making comments about what each step does along the way.</li> <li>We haven't covered fine-tuning with TensorFlow Hub in this notebook, but if you'd like to know more, go through the <a href=https://www.tensorflow.org/hub/tf2_saved_model#fine-tuning>fine-tuning a TensorFlow Hub model tutorial</a> on the TensorFlow homepage.How to fine-tune a tensorflow hub model: </li> <li>Look into <a href=https://www.wandb.com/experiment-tracking>experiment tracking with Weights &amp; Biases</a>, how could you integrate it with our existing TensorBoard logs?</li> </ul> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../..", "features": ["navigation.tabs", "navigation.tabs.sticky", "navigation.instant", "navigation.path", "navigation.indexes", "navigation.top", "navigation.tracking"], "search": "../../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src=../../../assets/javascripts/bundle.c8b220af.min.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> <script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body> </html>